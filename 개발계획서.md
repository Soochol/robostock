# 주식 장기투자 모델 개발 계획서

## 1. 프로젝트 개요

### 1.1 목적

- **산업 변화 트렌드 포착**: 거래량 블록(1번+2번) 발생으로 자금 유입 시그널 탐지
- **장기 고수익 종목 선별**: 50% 이상 상승 가능성이 높은 종목 사전 식별
- **AI 기반 의사결정**: 비지도/지도 학습으로 팩터 분석 및 패턴 예측

### 1.2 목표

- **1번+2번 거래량 블록 자동 탐지**: 10년간 KOSPI/KOSDAQ 전 종목 분석
- **수익률 구간별 차별 팩터 발견**: 비지도 학습으로 Level 1~4(50%~1000%+) 구분 요인 도출
- **성공 패턴 예측 시스템**: 지도 학습으로 알려진 성공 패턴 템플릿 기반 신규 케이스 성공 확률 계산
- **백테스팅 검증**: 과거 10년 데이터로 전략 유효성 검증 및 최적화

## 2. 개발 범위

### 2.1 기술적 분석 (산업 변화 트렌드 포착)

> **핵심 전략**: 산업 변화 트렌드의 시작을 확인하고 투자
> - 트렌드 변화/시작 판단 기준: **종목/섹터/산업에 자금 유입 여부**

---

### 2.1 주가 트렌드의 변화 (Price Trend Change)

> **정의**: 대규모 거래량 발생을 통한 주가 트렌드 변화 포착
> **의미**: 산업 변화 트렌드의 시작 → **역사적 최대 거래량 발생이 핵심 시그널**

#### 2.1.1 주가 트렌드 변화의 탐지

> **모델링 정의**: 산업 변화 트렌드 시작을 알리는 **자금 유입 시그널 이벤트**

- **1번 거래량 블록**

  - **정의**: 2년래 최대 거래량 (양봉/음봉 모두 가능)
  - **목적**: 이상(anomaly) 거래량 발생 시점 탐지

  - **D일 거래량**
    - `d_volume`: D일 거래량
    - `d_volume_vs_2y_max`: 2년래 최대 거래량 대비 비율 (%) - 100% 이상이어야 함
    - `is_2y_max`: 2년래 최대 거래량 여부 (Boolean)
    - `d_date`: D일 날짜

  - **D일 거래대금**
    - **조건**: D일 거래대금 ≥ 500억원
    - **포인트 시스템**: 거래대금에 따라 비선형 점수 부여
    - `d_trading_value`: D일 거래대금 (억원)
    - `is_500b_value`: 거래대금 500억원 이상 여부 (Boolean)
    - `trading_value_score`: 거래대금 점수 (10점 만점)
      - 500억원 = 1점
      - 1,000억원 = 5점
      - 2,000억원 이상 = 10점

  - **D일 가격 데이터**
    - `d_open`: D일 시가
    - `d_close`: D일 종가
    - `d_high`: D일 고가
    - `d_low`: D일 저가

  - **D일 신고가 분석** (1번 블록 기준)
    - `is_new_high_2y`: 2년래 신고가 여부 (Boolean)
    - `max_2y`: 2년 내 최고가

  - **D일 수급 분석**
    - `d_institutional_net_buy`: 기관 순매수 금액 (원)
    - `d_foreign_net_buy`: 외국인 순매수 금액 (원)
    - `d_foreign_institutional_net_buy`: 외국인+기관 순매수 금액 (원)
    - `d_individual_net_buy`: 개인 순매수 금액 (원)
    - `is_d_institutional_buying`: D일 기관 순매수 여부 (Boolean)
    - `is_d_foreign_buying`: D일 외국인 순매수 여부 (Boolean)
    - `is_d_foreign_institutional_buying`: D일 외국인+기관 순매수 여부 (Boolean)
    - `is_d_individual_buying`: D일 개인 순매수 여부 (Boolean)

  - **1번 거래량 확정 조건**
    - `is_2y_max = True` (2년래 최대 거래량)
    - `is_500b_value = True` (거래대금 500억원 이상)
    - **위 2가지 조건 모두 만족 시 1번 거래량 블록 확정**

- **2번 거래량 블록**
  - **정의**: 1번 거래량 블록 발생 이후 6개월 내, 특정 패턴 조건과 가격 조건을 충족하는 거래량
  - **목적**: 트렌드 변화 시작 및 자금 유입 지속성 확인

  - **트리거 거래량 D (D-Day)**
    - **정의**: 1번 거래량 블록 발생 이후 6개월 내 발생, 1번 거래량 블록의 거래량 대비 80% 이상
    - **D일 거래량**
      - `d_volume`: D일 거래량
      - `d_volume_vs_primary`: 1번 거래량 블록 D일 거래량 대비 비율 (%)
      - `is_80pct_of_primary`: 1번 거래량 블록 대비 80% 이상 여부 (Boolean)
      - `days_from_primary`: 1번 거래량 블록 발생일로부터 경과 일수
      - `is_within_6months`: 6개월 내 발생 여부 (Boolean)

    - **D일 거래대금**
      - **조건**: 트리거 거래량 발생일 거래대금 ≥ 500억원
      - **포인트 시스템**: 거래대금에 따라 비선형 점수 부여
      - `d_trading_value`: D일 거래대금 (억원)
      - `is_500b_value`: 거래대금 500억원 이상 여부 (Boolean)
      - `trading_value_score`: 거래대금 점수 (10점 만점)
        - 500억원 = 1점
        - 1,000억원 = 5점
        - 2,000억원 이상 = 10점

    - **D일 가격 데이터**
      - `d_open`: D일 시가
      - `d_close`: D일 종가
      - `d_high`: D일 고가
      - `d_low`: D일 저가

    - **D일 수급 분석**
      - `d_institutional_net_buy`: 기관 순매수 금액 (원)
      - `d_foreign_net_buy`: 외국인 순매수 금액 (원)
      - `d_foreign_institutional_net_buy`: 외국인+기관 순매수 금액 (원)
      - `d_individual_net_buy`: 개인 순매수 금액 (원)
      - `is_d_institutional_buying`: D일 기관 순매수 여부 (Boolean)
      - `is_d_foreign_buying`: D일 외국인 순매수 여부 (Boolean)
      - `is_d_foreign_institutional_buying`: D일 외국인+기관 순매수 여부 (Boolean)
      - `is_d_individual_buying`: D일 개인 순매수 여부 (Boolean)

  - **트리거 거래량 D+1**
    - **정의**: D 다음 날로, D와 D+1이 함께 확정되는 조건
    - **D+1 거래량 조건**: `d1_volume >= d_volume × 0.5`
    - **D+1 고가 조건**: `d1_high > d_high` (D+1의 고가가 D의 고가보다 높아야 함)
    - **중요**: D+1 조건이 충족되어야 비로소 **D가 정의**됨 (최소 D+1까지 확인 필수)

    - **D+1일 거래량**
      - `d1_volume`: D+1일 거래량
      - `d1_volume_vs_d`: D 거래량 대비 비율 (%)

    - **D+1일 가격 데이터**
      - `d1_open`: D+1일 시가
      - `d1_close`: D+1일 종가
      - `d1_high`: D+1일 고가
      - `d1_low`: D+1일 저가
      - `is_d1_high_breakout`: D+1 고가 > D 고가 여부 (Boolean)

    - **D+1일 수급 분석**
      - `d1_institutional_net_buy`: 기관 순매수 금액 (원)
      - `d1_foreign_net_buy`: 외국인 순매수 금액 (원)
      - `d1_foreign_institutional_net_buy`: 외국인+기관 순매수 금액 (원)
      - `d1_individual_net_buy`: 개인 순매수 금액 (원)
      - `is_d1_institutional_buying`: D+1일 기관 순매수 여부 (Boolean)
      - `is_d1_foreign_buying`: D+1일 외국인 순매수 여부 (Boolean)
      - `is_d1_foreign_institutional_buying`: D+1일 외국인+기관 순매수 여부 (Boolean)
      - `is_d1_individual_buying`: D+1일 개인 순매수 여부 (Boolean)

    - **D+1 검증**
      - `is_d1_qualified`: D+1 조건 충족 여부 (Boolean) - 거래량 + 고가 조건 모두 만족

  - **트리거 거래량 D+2**
    - **정의**: D+1 다음 날로, D+2 조건 충족 시 D, D+2가 확정
    - **D+2 거래량 조건**: `d2_volume >= d_volume × 0.5`
    - **D+2 고가 조건**: `d2_high > d_high` (D+2의 고가가 D의 고가보다 높아야 함)

    - **D+2일 거래량**
      - `d2_volume`: D+2일 거래량
      - `d2_volume_vs_d`: D 거래량 대비 비율 (%)

    - **D+2일 가격 데이터**
      - `d2_open`: D+2일 시가
      - `d2_close`: D+2일 종가
      - `d2_high`: D+2일 고가
      - `d2_low`: D+2일 저가
      - `is_d2_high_breakout`: D+2 고가 > D 고가 여부 (Boolean)

    - **D+2일 수급 분석**
      - `d2_institutional_net_buy`: 기관 순매수 금액 (원)
      - `d2_foreign_net_buy`: 외국인 순매수 금액 (원)
      - `d2_foreign_institutional_net_buy`: 외국인+기관 순매수 금액 (원)
      - `d2_individual_net_buy`: 개인 순매수 금액 (원)
      - `is_d2_institutional_buying`: D+2일 기관 순매수 여부 (Boolean)
      - `is_d2_foreign_buying`: D+2일 외국인 순매수 여부 (Boolean)
      - `is_d2_foreign_institutional_buying`: D+2일 외국인+기관 순매수 여부 (Boolean)
      - `is_d2_individual_buying`: D+2일 개인 순매수 여부 (Boolean)

    - **D+2 검증**
      - `is_d2_qualified`: D+2 조건 충족 여부 (Boolean) - 거래량 + 고가 조건 모두 만족

  - **2번 거래량 블록 확정 조건 (종합)**
    - **필수 조건 1: 1번 블록 고가 돌파**
      - 2번 블록의 D, D+1, D+2 중 **최소 하나의 고가**가 1번 거래량 블록 D일 고가보다 커야 함
      - `max(d_high, d1_high, d2_high) > primary_d_high`

    - **필수 조건 2: 거래대금 조건**
      - 2번 블록의 D, D+1, D+2 중 **최소 하나의 거래대금**이 2000억원 이상이어야 함
      - `max(d_trading_value, d1_trading_value, d2_trading_value) >= 2000억원`

    - **필수 조건 3: 패턴 조건**
      - D + D+1, D + D+2, 또는 D + D+1 + D+2 조건을 만족해야 함
      - 패턴 1: D 조건 충족 + D+1 조건 충족
      - 패턴 2: D 조건 충족 + D+2 조건 충족
      - 패턴 3: D 조건 충족 + D+1 조건 충족 + D+2 조건 충족
      - **중요**: 패턴 1, 패턴 2, 패턴 3 중 하나만 만족하면 됨

    - **필수 조건 4: 기간 가격 조건**
      - 2번 거래량 블록의 D 거래량 발생 이후, 추세적으로 1번 거래량 블록의 D일 고가 위에서 14일 이상 종가를 형성하는 기간이 존재

    - **최종 확정**
      - 위 4가지 필수 조건을 **모두 만족**하면 2번 거래량 블록 확정

---

#### 2.1.2 거래량 블록 범위 정의 (Block Range Definition)

---

### 1번 거래량 블록 범위

**정의:**
```
블록 시작: 1번 거래량 D일
블록 종료: 2번 거래량 D일 발생 직전일
블록 기간: 1번 D일 ~ 2번 D일 전날
```

**목적:**
- 1번 블록 발생 후 2번 블록 발생까지의 중간 기간 분석
- 이 기간 동안의 주가/거래량 움직임이 2번 블록의 성공 여부에 영향을 줄 수 있음

**데이터 구조:**
```python
block_1_range = {
    # 블록 범위
    "block_start_date": "2019-03-15",    # 1번 거래량 D일
    "block_end_date": "2019-08-19",      # 2번 거래량 D일 전날
    "block_duration_days": 157,           # 블록 기간

    # 가격 정보
    "block_high": 48000,                 # 블록 기간 중 최고가
    "block_high_date": "2019-05-20",     # 최고가 달성일
    "block_low": 42000,                  # 블록 기간 중 최저가
    "block_low_date": "2019-07-10",      # 최저가 발생일

    # 1번 D일 가격 데이터
    "start_open": 46500,                 # 1번 D일 시가
    "start_high": 48000,                 # 1번 D일 고가
    "start_low": 46000,                  # 1번 D일 저가
    "start_close": 47000,                # 1번 D일 종가

    # 1번 D일 수급 데이터 (당일 스냅샷)
    # ★ 중요: 여기는 1번 블록 D일 '당일'의 순매수/순매도 여부만 기록
    #         기간 트렌드 분석은 '2.3 수급 분석' 섹션 참조
    "d_institutional_net_buy": 5000000000,        # 기관 순매수 금액 (원)
    "d_foreign_net_buy": 8000000000,              # 외국인 순매수 금액 (원)
    "d_foreign_institutional_net_buy": 13000000000,  # 외국인+기관 순매수 (원)
    "d_individual_net_buy": -13000000000,         # 개인 순매수 금액 (원)
    "is_d_institutional_buying": True,            # D일 기관 순매수 여부
    "is_d_foreign_buying": True,                  # D일 외국인 순매수 여부
    "is_d_foreign_institutional_buying": True,    # D일 외국인+기관 순매수 여부
    "is_d_individual_buying": False,              # D일 개인 순매수 여부

    # 거래량 정보
    "avg_daily_volume": 500000,          # 블록 기간 평균 일 거래량
    "total_volume": 78500000,            # 블록 기간 총 거래량

    # 1번 블록 대비 분석
    "days_to_block2": 157,               # 1번 블록 → 2번 블록까지 소요일
    "is_within_6months": True            # 6개월 내 2번 블록 발생 여부
}
```

**주요 변수:**
- `block_start_date`: 1번 거래량 D일
- `block_end_date`: 2번 거래량 D일 전날
- `block_high`: 1번~2번 블록 사이 기간 중 최고가
- `days_to_block2`: 1번 블록 발생 후 2번 블록까지 소요일 (최대 6개월 = 180일)

**시각화 예시:**

```
주가 차트:
                  ↗ 최고가 48,000원 (5/20)
                ↗   ↘
              ↗       ↘
            ↗           ↘
D일 (3/15)                ↘
    ↑                       ↘
블록 시작                     └─ 2번 블록 직전 (8/19)
|←──── 블록 기간 157일 ────→|      ↑
                                블록 종료

거래량:
D일 (3/15): ████████████ (1번 거래량 발생, 2년래 최대)
3/20:       ██████
4/1:        ████
5/1:        ███
5/20:       ████ (최고가 달성일)
6/1:        ███
7/1:        ██
8/1:        ██
8/19:       █ (2번 블록 발생 직전)
```

---

### 2번 거래량 블록 범위

> **핵심 개념**: 2번 거래량 블록을 단순히 D, D+1, D+2 3일이 아닌, **D일부터 주가가 60일 이동평균선으로 회귀할 때까지의 전체 기간**을 하나의 블록으로 정의

**배경:**
- 실제 차트에서 2번 거래량 D일 발생 이후, 수일~수주간 지속적인 거래량 증가 및 주가 상승 추세가 나타남
- 이 추세가 끝나는 시점을 명확히 정의해야 **블록 기간 중 최고가**를 수익률 계산 기준점으로 사용 가능

**블록 종료 조건: 60일 이동평균선 회귀**

**정의:**
```
블록 시작: D일 (2번 거래량 발생일)
블록 종료: 주가가 60일 이동평균선을 터치하거나 하방 이탈하는 첫 시점
블록 기준가: 블록 기간(D일 ~ 블록 종료일) 중 최고가
```

**알고리즘:**
```python
def detect_block_range(df, d_date):
    """
    2번 거래량 블록 범위 탐지: D일 ~ 60이평선 회귀 시점
    """
    # 60일 이동평균선 계산
    df['ma60'] = df['close'].rolling(window=60).mean()

    # D일 이후 주가 추적 (최대 6개월)
    for i in range(1, 180):
        current_date = d_date + timedelta(days=i)

        if current_date not in df.index:
            continue

        close = df.loc[current_date, 'close']
        low = df.loc[current_date, 'low']
        ma60 = df.loc[current_date, 'ma60']

        # 조건: 저가가 60이평선 터치 또는 종가가 60이평선 하방 이탈
        if low <= ma60 or close < ma60:
            return {
                "block_start_date": d_date,
                "block_end_date": current_date,
                "block_duration_days": i,
                "block_high": df.loc[d_date:current_date, 'high'].max(),
                "block_high_date": df.loc[d_date:current_date, 'high'].idxmax(),
                "ma60_at_end": ma60,
                "end_reason": "터치" if low <= ma60 else "하방이탈"
            }

    # 6개월 내 회귀 없으면 6개월을 블록으로 간주
    end_date = d_date + timedelta(days=180)
    return {
        "block_start_date": d_date,
        "block_end_date": end_date,
        "block_duration_days": 180,
        "block_high": df.loc[d_date:end_date, 'high'].max(),
        "note": "6개월 내 60이평선 회귀 없음 (강한 상승 추세)"
    }
```

**데이터 구조:**

```python
block_2_range = {
    # ========== 블록 범위 정보 ==========
    # 블록 시간 범위
    "d_date": "2019-08-20",              # D일 (블록 시작)
    "block_end_date": "2019-10-15",      # 60이평선 회귀일
    "block_duration_days": 56,            # 블록 기간

    # 가격 정보
    "block_high": 52000,                 # ★ 수익률 계산 기준점
    "block_high_date": "2019-09-10",     # 최고가 달성일
    "block_low": 48000,                  # 블록 기간 중 최저가

    # ========== D, D+1, D+2 가격 데이터 ==========
    # D일 가격 데이터
    "d_date_open": 49500,                # D일 시가
    "d_date_high": 51000,                # D일 고가
    "d_date_low": 49000,                 # D일 저가
    "d_date_close": 50000,               # D일 종가

    # D+1일 가격 데이터
    "d1_date": "2019-08-21",             # D+1일 날짜
    "d1_open": 50500,                    # D+1일 시가
    "d1_high": 52000,                    # D+1일 고가
    "d1_low": 50000,                     # D+1일 저가
    "d1_close": 51500,                   # D+1일 종가

    # D+2일 가격 데이터
    "d2_date": "2019-08-22",             # D+2일 날짜
    "d2_open": 51000,                    # D+2일 시가
    "d2_high": 51800,                    # D+2일 고가
    "d2_low": 50500,                     # D+2일 저가
    "d2_close": 51200,                   # D+2일 종가

    # ========== D, D+1, D+2 수급 데이터 (당일 스냅샷) ==========
    # ★ 중요: 여기는 각 날짜의 '당일' 순매수/순매도 여부만 기록
    #         기간 트렌드 분석은 '2.3 수급 분석' 섹션 참조

    # D일 수급 데이터 (당일)
    "d_institutional_net_buy": 12000000000,       # D일 기관 순매수 (원)
    "d_foreign_net_buy": 15000000000,             # D일 외국인 순매수 (원)
    "d_foreign_institutional_net_buy": 27000000000,  # D일 외국인+기관 순매수 (원)
    "d_individual_net_buy": -27000000000,         # D일 개인 순매수 (원)
    "is_d_institutional_buying": True,            # D일 기관 순매수 여부
    "is_d_foreign_buying": True,                  # D일 외국인 순매수 여부
    "is_d_foreign_institutional_buying": True,    # D일 외국인+기관 순매수 여부
    "is_d_individual_buying": False,              # D일 개인 순매수 여부

    # D+1일 수급 데이터 (당일)
    "d1_institutional_net_buy": 8000000000,       # D+1일 기관 순매수 (원)
    "d1_foreign_net_buy": 10000000000,            # D+1일 외국인 순매수 (원)
    "d1_foreign_institutional_net_buy": 18000000000,  # D+1일 외국인+기관 순매수 (원)
    "d1_individual_net_buy": -18000000000,        # D+1일 개인 순매수 (원)
    "is_d1_institutional_buying": True,           # D+1일 기관 순매수 여부
    "is_d1_foreign_buying": True,                 # D+1일 외국인 순매수 여부
    "is_d1_foreign_institutional_buying": True,   # D+1일 외국인+기관 순매수 여부
    "is_d1_individual_buying": False,             # D+1일 개인 순매수 여부

    # D+2일 수급 데이터 (당일)
    "d2_institutional_net_buy": 3000000000,       # D+2일 기관 순매수 (원)
    "d2_foreign_net_buy": 5000000000,             # D+2일 외국인 순매수 (원)
    "d2_foreign_institutional_net_buy": 8000000000,   # D+2일 외국인+기관 순매수 (원)
    "d2_individual_net_buy": -8000000000,         # D+2일 개인 순매수 (원)
    "is_d2_institutional_buying": True,           # D+2일 기관 순매수 여부
    "is_d2_foreign_buying": True,                 # D+2일 외국인 순매수 여부
    "is_d2_foreign_institutional_buying": True,   # D+2일 외국인+기관 순매수 여부
    "is_d2_individual_buying": False,             # D+2일 개인 순매수 여부

    # 블록 종료일 가격 데이터
    "block_end_open": 46500,             # 블록 종료일 시가
    "block_end_high": 47000,             # 블록 종료일 고가
    "block_end_low": 45500,              # 블록 종료일 저가
    "block_end_close": 46000,            # 블록 종료일 종가

    # 60이평선 정보
    "ma60_at_d_date": 45000,             # D일 시점 60이평선
    "ma60_at_end": 46500,                # 블록 종료일 60이평선
    "end_reason": "터치",                 # 종료 사유: "터치" or "하방이탈"

    # 거래량 정보
    "total_volume": 80000000,            # 블록 기간 총 거래량
    "avg_daily_volume": 1428571,         # 블록 기간 평균 일 거래량
    "peak_volume_date": "2019-08-20",    # D일 (최대 거래량 발생일)

    # ========== 패턴 만족 여부 ==========
    "is_d_plus_d1_pattern": True,        # D + D+1 패턴 만족 여부
    "is_d_plus_d2_pattern": False,       # D + D+2 패턴 만족 여부
    "is_d_plus_d1_d2_pattern": False,    # D + D+1 + D+2 모두 만족 여부
    "matched_pattern": "D+D+1",          # 만족한 패턴: "D+D+1" or "D+D+2" or "D+D+1+D+2"

    # ========== 신고가 분석 (2.1.3에서 추가) ==========
    # 신고가 여부
    "is_new_high_2y": True,              # 2년래 신고가
    "is_new_high_5y": False,             # 5년래 신고가 아님
    "is_new_high_10y": False,            # 10년래 신고가 아님
    "is_all_time_high": False,           # 역사적 신고가 아님

    # 신고가 등급
    "new_high_score": 4,                 # 신고가 점수 (10점 만점) - C등급
    "new_high_grade": "C",               # 신고가 등급 (S/A/B/C/D/E/F)

    # 과거 최고가 정보
    "max_2y": 52000,                     # 2년 내 최고가
    "max_2y_date": "2019-09-10",         # 2년 내 최고가 달성일
    "days_since_2y_high": 0,             # 2년래 최고가 이후 경과일 (현재가 최고가)

    "max_5y": 68000,                     # 5년 내 최고가
    "max_5y_date": "2017-06-15",         # 5년 내 최고가 달성일
    "days_since_5y_high": 827,           # 5년래 최고가 이후 경과일

    "max_10y": 75000,                    # 10년 내 최고가
    "max_10y_date": "2015-03-20",        # 10년 내 최고가 달성일
    "days_since_10y_high": 1644,         # 10년래 최고가 이후 경과일

    "max_all_time": 85000,               # 역사적 최고가 (ATH)
    "ath_date": "2014-09-10",            # 역사적 고점 달성일
    "days_since_ath": 1825,              # 역사적 고점 이후 경과일
}
```

---

### 3번 거래량 블록 (추가 거래량 블록)

> **핵심 개념**: 2번 거래량 블록 이후 추가적인 대량 거래가 발생하며, 외국인+기관 쌍끌이 매수가 나타나는 시점

**정의:**
```
3번 거래량 블록 발생 조건:
1. 2번 거래량 블록 D, D+1, D+2 중 최대 거래량일 대비 거래량이 15% 이상 발생
2. 해당일 고가가 2번 거래량 블록 최고점(block_high) 대비 ±12% 이내
3. 외국인+기관 쌍끌이 매수 발생 (둘 다 순매수)
```

**목적:**
- 2번 블록 이후 **추가 자금 유입** 확인
- **외국인+기관 쌍끌이** 수급이 성공의 핵심 팩터인지 검증
- 수급 강도(거래대금 대비 매수 비율)와 성공률의 상관관계 분석

**알고리즘:**
```python
def detect_block_3(df, block_2_info):
    """
    3번 거래량 블록 탐지
    """
    # 2번 블록 정보
    max_volume_date = block_2_info['peak_volume_date']  # D, D+1, D+2 중 최대 거래량일
    max_volume = block_2_info['peak_volume']            # 최대 거래량
    block_2_high = block_2_info['block_high']           # 2번 블록 최고가

    # 2번 블록 D일 이후 추적 (최대 6개월)
    start_date = block_2_info['d_date']

    for i in range(1, 180):
        current_date = start_date + timedelta(days=i)

        if current_date not in df.index:
            continue

        # 조건 1: 거래량이 2번 블록 최대 거래량 대비 15% 이상
        current_volume = df.loc[current_date, 'volume']
        if current_volume < max_volume * 0.15:
            continue

        # 조건 2: 고가가 2번 블록 최고가 대비 ±12% 이내
        current_high = df.loc[current_date, 'high']
        price_diff_pct = (current_high - block_2_high) / block_2_high * 100
        if abs(price_diff_pct) > 12:
            continue

        # 조건 3: 외국인+기관 쌍끌이 매수
        institutional_buy = df.loc[current_date, 'institutional_net_buy']
        foreign_buy = df.loc[current_date, 'foreign_net_buy']

        if institutional_buy > 0 and foreign_buy > 0:
            # 3번 블록 발견
            return {
                "block_3_date": current_date,
                "volume": current_volume,
                "volume_ratio_vs_block2": current_volume / max_volume,
                "high": current_high,
                "price_diff_from_block2_pct": price_diff_pct,
                "institutional_buy": institutional_buy,
                "foreign_buy": foreign_buy,
                "combined_buy": institutional_buy + foreign_buy,
                "is_both_buying": True,
            }

    return None  # 3번 블록 없음
```

**데이터 구조:**
```python
block_3 = {
    # ========== 블록 발생 정보 ==========
    "has_block_3": True,                     # 3번 블록 발생 여부
    "block_3_date": "2019-09-25",            # 3번 블록 발생일
    "days_from_block_2": 36,                 # 2번 블록 D일로부터 일수

    # ========== 거래량 정보 ==========
    "volume": 15000000,                      # 3번 블록 거래량
    "block_2_max_volume": 80000000,          # 2번 블록 최대 거래량 (비교 기준)
    "volume_ratio_vs_block2": 0.1875,        # 2번 블록 대비 거래량 비율 (18.75%)
    "is_volume_condition_met": True,         # 거래량 조건 만족 (15% 이상)

    # ========== 가격 정보 ==========
    "open": 50000,                           # 시가
    "high": 52500,                           # 고가
    "low": 49500,                            # 저가
    "close": 51500,                          # 종가

    "block_2_high": 52000,                   # 2번 블록 최고가 (비교 기준)
    "price_diff_from_block2": 500,           # 2번 블록 최고가 대비 차이 (원)
    "price_diff_pct": 0.96,                  # 2번 블록 최고가 대비 차이 (%)
    "is_price_condition_met": True,          # 가격 조건 만족 (±12% 이내)

    # ========== 수급 정보 (외국인+기관 쌍끌이) ==========
    "institutional_net_buy": 8500000000,     # 기관 순매수 금액 (원)
    "foreign_net_buy": 12000000000,          # 외국인 순매수 금액 (원)
    "individual_net_buy": -20500000000,      # 개인 순매수 금액 (원)

    "combined_buy": 20500000000,             # 외국인+기관 합산 매수 (원)
    "is_both_buying": True,                  # 쌍끌이 여부 (외국인+기관 모두 순매수)

    # ========== 수급 강도 분석 ==========
    "trading_value": 850000000000,           # 당일 거래대금 (원)
    "buy_ratio_of_volume": 2.41,             # 거래대금 대비 쌍끌이 매수 비율 (%)
    "supply_strength_score": 7.5,            # 수급 강도 점수 (0-10)

    # 수급 강도 등급
    "supply_strength_grade": "B",            # S(10%), A(5~10%), B(3~5%), C(1~3%), D(<1%)
}
```

**수급 강도 등급 기준:**
```python
def calculate_supply_strength_grade(buy_ratio_of_volume):
    """
    거래대금 대비 쌍끌이 매수 비율로 수급 강도 등급 산정
    """
    if buy_ratio_of_volume >= 10:
        return "S", 10.0  # 초강력 수급
    elif buy_ratio_of_volume >= 5:
        return "A", 8.5   # 강력 수급
    elif buy_ratio_of_volume >= 3:
        return "B", 7.0   # 양호 수급
    elif buy_ratio_of_volume >= 1:
        return "C", 5.0   # 보통 수급
    else:
        return "D", 3.0   # 약한 수급
```

---

### 4번 거래량 블록 (추가 거래량 블록 2차)

**정의:**
```
4번 거래량 블록 발생 조건:
1. 3번 거래량 블록 이후, 2번 블록 최대 거래량일 대비 15% 이상 발생
2. 해당일 고가가 2번 거래량 블록 최고점 대비 ±12% 이내
3. 외국인+기관 쌍끌이 매수 발생
```

**목적:**
- **반복적인 자금 유입** 패턴 확인
- 3번 블록 → 4번 블록 연속 발생 시 성공률이 더 높은지 검증
- 수급 강도의 지속성과 Level 상승의 관계 분석

**데이터 구조:**
```python
block_4 = {
    # ========== 블록 발생 정보 ==========
    "has_block_4": True,                     # 4번 블록 발생 여부
    "block_4_date": "2019-10-18",            # 4번 블록 발생일
    "days_from_block_2": 59,                 # 2번 블록 D일로부터 일수
    "days_from_block_3": 23,                 # 3번 블록으로부터 일수

    # ========== 거래량 정보 ==========
    "volume": 18000000,                      # 4번 블록 거래량
    "block_2_max_volume": 80000000,          # 2번 블록 최대 거래량 (비교 기준)
    "volume_ratio_vs_block2": 0.225,         # 2번 블록 대비 거래량 비율 (22.5%)
    "is_volume_condition_met": True,         # 거래량 조건 만족 (15% 이상)

    # ========== 가격 정보 ==========
    "open": 51000,                           # 시가
    "high": 53000,                           # 고가
    "low": 50500,                            # 저가
    "close": 52500,                          # 종가

    "block_2_high": 52000,                   # 2번 블록 최고가 (비교 기준)
    "price_diff_from_block2": 1000,          # 2번 블록 최고가 대비 차이 (원)
    "price_diff_pct": 1.92,                  # 2번 블록 최고가 대비 차이 (%)
    "is_price_condition_met": True,          # 가격 조건 만족 (±12% 이내)

    # ========== 수급 정보 (외국인+기관 쌍끌이) ==========
    "institutional_net_buy": 10000000000,    # 기관 순매수 금액 (원)
    "foreign_net_buy": 15000000000,          # 외국인 순매수 금액 (원)
    "individual_net_buy": -25000000000,      # 개인 순매수 금액 (원)

    "combined_buy": 25000000000,             # 외국인+기관 합산 매수 (원)
    "is_both_buying": True,                  # 쌍끌이 여부

    # ========== 수급 강도 분석 ==========
    "trading_value": 920000000000,           # 당일 거래대금 (원)
    "buy_ratio_of_volume": 2.72,             # 거래대금 대비 쌍끌이 매수 비율 (%)
    "supply_strength_score": 7.8,            # 수급 강도 점수 (0-10)
    "supply_strength_grade": "B",            # 수급 강도 등급
}
```

---

### 3번/4번 블록 패턴 분석

**데이터 구조:**
```python
additional_blocks_pattern = {
    # 블록 발생 현황
    "has_block_3": True,
    "has_block_4": True,
    "total_additional_blocks": 2,            # 3번, 4번 블록 개수

    # 블록 간격 분석
    "block_2_to_3_days": 36,                 # 2번 → 3번 간격
    "block_3_to_4_days": 23,                 # 3번 → 4번 간격
    "is_frequent_blocks": True,              # 빈번한 블록 발생 (간격 30일 이하)

    # 수급 패턴 분석
    "block_3_supply_grade": "B",             # 3번 블록 수급 강도
    "block_4_supply_grade": "B",             # 4번 블록 수급 강도
    "is_consistent_supply": True,            # 지속적 강한 수급 (B등급 이상)

    # 수급 강도 추세
    "supply_trend": "유지",                   # 상승/유지/하락
    "avg_supply_score": 7.65,                # 3번, 4번 평균 수급 점수

    # 패턴 종합
    "pattern_type": "연속 쌍끌이",            # "연속 쌍끌이" / "단발 쌍끌이" / "없음"
    "pattern_strength": "강",                 # 강/중/약
}
```

**수익률 계산:**
```python
# 기준점: 블록 기간 중 최고가
baseline_price = block_2_range["block_high"]  # 52,000원

# 목표: 5년 내 기준점 대비 50% 이상 상승
target_price_50pct = baseline_price * 1.5  # 78,000원
target_price_100pct = baseline_price * 2.0  # 104,000원
target_price_1000pct = baseline_price * 11.0  # 572,000원

# 실제 달성 여부 추적 (5년간)
max_price_5years = df.loc[block_end_date:block_end_date+5years, 'high'].max()
actual_return_pct = (max_price_5years / baseline_price - 1) * 100

# Level 분류
if actual_return_pct >= 1000:
    return_level = 4  # Level 4
elif actual_return_pct >= 300:
    return_level = 3  # Level 3
elif actual_return_pct >= 100:
    return_level = 2  # Level 2
elif actual_return_pct >= 50:
    return_level = 1  # Level 1
else:
    return_level = 0  # 실패
```

**시각화 예시:**
```
주가 차트:
                  ↗ 최고가 52,000원 (9/10)
                ↗   ↘
              ↗       ↘
            ↗           ↘
          ↗               ↘ ← 60이평선 터치 (10/15)
D일 (8/20)                 └─ 블록 종료
    ↑                         ↑
블록 시작                  블록 종료
|←──── 블록 기간 56일 ────→|

거래량:
D일 (8/20): ████████████ (2번 거래량 발생)
8/25:       ██████
9/1:        ████
9/10:       ███ (최고가 달성일)
9/20:       ██
10/1:       ██
10/15:      █ (평상시 수준 + 60이평선 터치)
```

**주요 변수:**
- `block_start_date`: D일
- `block_end_date`: 60이평선 터치/하방이탈일
- `block_high`: 블록 기간 중 최고가 (**수익률 계산 기준점**)
- `block_duration_days`: 블록 지속 기간

---

#### 2.1.3 블록 최고가 신고가 여부 분석

> **핵심 개념**: 블록 최고가가 과거 대비 얼마나 의미있는 고점인지 판단 (신고가 = 강한 모멘텀)

**배경:**
- 블록 최고가가 **역사적 신고가** 또는 **장기 신고가**일 경우 → 강한 상승 모멘텀, 고수익 가능성 높음
- 블록 최고가가 과거 고점 대비 낮은 수준일 경우 → 약한 반등, 저수익 가능성

**신고가 판단 기준:**

```python
def analyze_block_high_significance(df, block_high_date, block_high_price):
    """
    블록 최고가가 과거 대비 어느 수준인지 분석
    """
    # 1) 2년래 신고가 여부
    max_2y = df.loc[block_high_date - 730days : block_high_date, 'high'].max()
    is_new_high_2y = block_high_price >= max_2y

    # 2) 5년래 신고가 여부
    max_5y = df.loc[block_high_date - 1825days : block_high_date, 'high'].max()
    is_new_high_5y = block_high_price >= max_5y

    # 3) 10년래 신고가 여부
    max_10y = df.loc[block_high_date - 3650days : block_high_date, 'high'].max()
    is_new_high_10y = block_high_price >= max_10y

    # 4) 역사적 신고가 여부 (상장 이후 전체 기간)
    max_all_time = df['high'].max()
    is_all_time_high = block_high_price >= max_all_time

    # 5) 신고가 등급 부여 (점수 시스템)
    new_high_score = 0
    if is_all_time_high:
        new_high_score = 10  # 최고 등급
    elif is_new_high_10y:
        new_high_score = 8
    elif is_new_high_5y:
        new_high_score = 6
    elif is_new_high_2y:
        new_high_score = 4
    else:
        # 신고가 아닐 경우: 과거 최고가 대비 몇 % 수준인지
        ratio_to_ath = (block_high_price / max_all_time) * 100
        if ratio_to_ath >= 90:
            new_high_score = 3  # 역사적 고점의 90% 이상
        elif ratio_to_ath >= 70:
            new_high_score = 2  # 70% 이상
        else:
            new_high_score = 1  # 70% 미만 (약한 반등)

    return {
        "is_new_high_2y": is_new_high_2y,
        "is_new_high_5y": is_new_high_5y,
        "is_new_high_10y": is_new_high_10y,
        "is_all_time_high": is_all_time_high,
        "new_high_score": new_high_score,
        "max_2y": max_2y,
        "max_5y": max_5y,
        "max_10y": max_10y,
        "max_all_time": max_all_time,
        "ratio_to_ath": (block_high_price / max_all_time) * 100
    }
```

**신고가 등급 시스템:**

| 등급 | 조건 | 점수 | 의미 | 예상 수익률 구간 |
|------|------|------|------|------------------|
| S등급 | 역사적 신고가 | 10점 | 최강 모멘텀 | Level 3~4 (300%+) |
| A등급 | 10년래 신고가 | 8점 | 강한 모멘텀 | Level 2~3 (100~300%) |
| B등급 | 5년래 신고가 | 6점 | 중강 모멘텀 | Level 2 (100~300%) |
| C등급 | 2년래 신고가 | 4점 | 보통 모멘텀 | Level 1~2 (50~100%) |
| D등급 | ATH의 90% 이상 | 3점 | 약한 모멘텀 | Level 1 (50~100%) |
| E등급 | ATH의 70~90% | 2점 | 약한 반등 | Level 0~1 (<50%) |
| F등급 | ATH의 70% 미만 | 1점 | 매우 약한 반등 | Level 0 (실패 가능성) |

**분석 예시:**

```python
# 케이스 1: 역사적 신고가 돌파
block_high = 85000
max_all_time = 82000
→ is_all_time_high = True
→ new_high_score = 10 (S등급)
→ 해석: 최강 모멘텀, Level 3~4 기대

# 케이스 2: 2년래 신고가, 하지만 5년 전 고점보다 낮음
block_high = 52000
max_2y = 50000
max_5y = 68000
max_all_time = 85000
→ is_new_high_2y = True
→ new_high_score = 4 (C등급)
→ ratio_to_ath = 61.2%
→ 해석: 보통 모멘텀, Level 1~2 기대

# 케이스 3: 과거 고점 대비 약한 반등
block_high = 45000
max_all_time = 85000
→ ratio_to_ath = 52.9%
→ new_high_score = 1 (F등급)
→ 해석: 매우 약한 반등, 실패 가능성 높음
```

**비지도 학습 활용:**

```python
# 3.6 비지도 학습에서 팩터로 활용
features = {
    # ... 기존 팩터들 ...
    "new_high_score": 4,
    "is_all_time_high": False,
    "ratio_to_ath": 61.2,
    # ...
}

# 분석 예상 결과:
# Level 4 달성 케이스:
#   - new_high_score 평균: 8.5 (대부분 10년래 또는 역사적 신고가)
#   - is_all_time_high: 70%
#
# Level 1 달성 케이스:
#   - new_high_score 평균: 3.2
#   - is_all_time_high: 10%
```

**시각화:**

```
역사적 차트 (10년):

85,000 ─────────────── ATH (2015년)
        |
        ↓ 5년 하락
        |
68,000 ─── 5년래 최고가 (2017년)

        ... 조정 ...

52,000 ─── ★ 블록 최고가 (2019년) ← 2년래 신고가
           ratio_to_ath = 61.2%
           new_high_score = 4점 (C등급)

45,000 ─── 120이평선
```

**중요도:**
- **신고가 여부**는 수익률 Level 예측에 **매우 중요한 팩터**
- 비지도 학습(3.6.3)에서 **팩터 중요도 분석** 시 상위권 예상
- 지도 학습(3.7)에서 **성공 패턴 템플릿**에도 신고가 여부 포함

---

## 2.2 재무제표 트렌드 분석

> **분석 기준 기간**: 1번 거래량 블록 D일 이전 2년 전부터 분석 현재 시점까지 지속적으로 분석

### 2.2.1 영업이익 트렌드

**실적 턴어라운드**
- 적자→흑자 전환 시점 포착
- 영업이익률 개선 추세
- 분기별/연도별 실적 증가율

**이익 지속성**
- 영업이익 연속 증가 분기 수
- 이익 안정성 및 변동성
- 컨센서스 대비 실적 서프라이즈

**수익성 지표**
- ROE, ROA 추이
- 영업이익률, 순이익률 변화
- 매출액 증가율 vs 이익 증가율

**데이터 구조:**
```python
operating_profit_analysis = {
    # 분석 기간
    "analysis_start_date": "2017-03-15",  # 1번 블록 D일 - 2년
    "primary_block_date": "2019-03-15",   # 1번 블록 D일
    "secondary_block_date": "2019-08-20", # 2번 블록 D일
    "current_date": "2020-03-15",         # 분석 현재 시점
    "total_analysis_quarters": 12,        # 총 분석 분기 수 (2년 전 ~ 현재)

    # 실적 턴어라운드
    "turnaround": {
        "has_turnaround": True,               # 턴어라운드 여부
        "turnaround_date": "2018-Q3",         # 흑자 전환 시점
        "quarters_since_turnaround": 3,       # 흑자 전환 후 경과 분기
        "operating_margin_improvement": 8.5,  # 영업이익률 개선폭 (%)
        "yoy_growth_rate": 125.5,             # 전년 동기 대비 성장률 (%)
        "qoq_growth_rate": 35.2,              # 전분기 대비 성장률 (%)
    },

    # 이익 지속성
    "profit_sustainability": {
        "consecutive_profit_quarters": 3,     # 연속 흑자 분기 수
        "consecutive_growth_quarters": 3,     # 연속 증가 분기 수
        "profit_volatility": 15.2,            # 이익 변동성 (표준편차 %)
        "stability_score": 7.8,               # 안정성 점수 (10점 만점)
        "consensus_surprise": 25.5,           # 컨센서스 대비 실적 서프라이즈 (%)
        "surprise_direction": "상향",          # 서프라이즈 방향
    },

    # 수익성 지표
    "profitability": {
        "roe_current": 15.2,                  # 현재 ROE (%)
        "roe_2y_ago": 5.5,                    # 2년 전 ROE (%)
        "roe_improvement": 9.7,               # ROE 개선폭 (%)

        "roa_current": 8.5,                   # 현재 ROA (%)
        "roa_2y_ago": 2.8,                    # 2년 전 ROA (%)
        "roa_improvement": 5.7,               # ROA 개선폭 (%)

        "operating_margin_current": 12.5,     # 현재 영업이익률 (%)
        "operating_margin_2y_ago": 4.0,       # 2년 전 영업이익률 (%)

        "net_margin_current": 9.2,            # 현재 순이익률 (%)
        "net_margin_2y_ago": 1.5,             # 2년 전 순이익률 (%)

        "revenue_growth_rate": 45.5,          # 매출 증가율 (%)
        "profit_growth_rate": 125.5,          # 이익 증가율 (%)
        "profit_leverage": 2.76,              # 이익 레버리지 (이익증가율/매출증가율)
    }
}
```

### 2.2.2 자본 총계 트렌드

**자본 총계 증가율**
- 분기별/연도별 자본 총계 변화
- 자본 총계 연속 증가 추이
- 자본 총계 증가 지속성

**자본 구조 분석**
- 자본금 변화
- 이익잉여금 누적 추이
- 부채비율 vs 자본 총계 관계

**데이터 구조:**
```python
equity_analysis = {
    # 분석 기간
    "analysis_start_date": "2017-03-15",  # 1번 블록 D일 - 2년
    "primary_block_date": "2019-03-15",   # 1번 블록 D일
    "secondary_block_date": "2019-08-20", # 2번 블록 D일
    "current_date": "2020-03-15",         # 분석 현재 시점
    "total_analysis_quarters": 12,        # 총 분석 분기 수 (2년 전 ~ 현재)

    # 자본 총계 증가율
    "equity_growth": {
        "total_equity_current": 500000000000,     # 현재 자본 총계 (원)
        "total_equity_2y_ago": 350000000000,      # 2년 전 자본 총계 (원)
        "equity_growth_amount": 150000000000,     # 자본 총계 증가액 (원)
        "equity_growth_rate": 42.9,               # 자본 총계 증가율 (%)
        "consecutive_growth_quarters": 7,         # 연속 증가 분기 수
        "avg_quarterly_growth_rate": 4.8,         # 평균 분기 증가율 (%)
        "growth_sustainability": "매우 강함",      # 증가 지속성
    },

    # 자본 구조 분석
    "capital_structure": {
        "paid_in_capital_current": 100000000000,  # 현재 자본금 (원)
        "paid_in_capital_2y_ago": 100000000000,   # 2년 전 자본금 (원)
        "capital_increase": False,                # 유상증자 여부

        "retained_earnings_current": 350000000000,  # 현재 이익잉여금 (원)
        "retained_earnings_2y_ago": 200000000000,   # 2년 전 이익잉여금 (원)
        "retained_earnings_growth": 150000000000,   # 이익잉여금 증가액 (원)
        "retained_earnings_growth_rate": 75.0,      # 이익잉여금 증가율 (%)

        "debt_ratio_current": 85.5,               # 현재 부채비율 (%)
        "debt_ratio_2y_ago": 125.5,               # 2년 전 부채비율 (%)
        "debt_ratio_improvement": -40.0,          # 부채비율 개선폭 (%)

        "structure_score": 8.5,                   # 자본 구조 점수 (10점 만점)
        "interpretation": "자본 총계 강한 증가 + 부채비율 개선 → 재무 건전성 향상"
    }
}
```

---

## 2.3 수급 분석

> **분석 기준 기간**: 2번 거래량 블록 D일부터 분석 현재 시점까지 지속적으로 분석

> **★ 중요**: 이 섹션은 **기간 트렌드 분석**입니다.
> - 1번/2번 블록의 D, D+1, D+2 수급 데이터 = **당일 스냅샷** (그날 순매수/순매도 여부)
> - 2.3 수급 분석 = **기간 추세** (연속 매수일, 총 매수금액, 보유비중 변화 등)

### 2.3.1 시장 참여자 동향

**공매도 분석**
- 공매도 거래량 및 비중
- 공매도 잔고 변화 추이
- 공매도 증가/감소 패턴

**프로그램 매매**
- 프로그램 순매수/순매도
- 차익거래/비차익거래 구분
- 프로그램 매매 비중

**데이터 구조:**
```python
market_participant_analysis = {
    # 분석 기간
    "analysis_start_date": "2019-08-20",  # 2번 블록 D일
    "block_end_date": "2019-10-15",       # 2번 블록 종료일 (60이평선 회귀)
    "current_date": "2020-03-15",         # 분석 현재 시점
    "total_analysis_days": 208,           # 총 분석 일수 (2번 블록 D일 ~ 현재)

    # 공매도 분석
    "short_selling": {
        "total_short_volume": 5000000,         # 기간 내 공매도 총 거래량
        "avg_short_ratio": 8.5,                # 평균 공매도 비중 (%)
        "short_balance_change": -2000000,      # 공매도 잔고 변화 (주)
        "short_pattern": "감소",                # 패턴: "증가" or "감소" or "안정"
        "peak_short_date": "2019-08-25",       # 공매도 최대 발생일
        "peak_short_ratio": 15.2,              # 최대 공매도 비중 (%)
    },

    # 프로그램 매매
    "program_trading": {
        "net_buy": 15000000000,                # 프로그램 순매수 (원)
        "arbitrage_buy": 8000000000,           # 차익거래 매수 (원)
        "non_arbitrage_buy": 7000000000,       # 비차익거래 매수 (원)
        "program_ratio": 35.5,                 # 프로그램 매매 비중 (%)
        "trend": "순매수",                      # 트렌드: "순매수" or "순매도"
    }
}
```

### 2.3.2 투자자별 수급

**외국인 투자자**
- 외국인 순매수/순매도
- 외국인 보유 비중 변화
- 외국인 매매 트렌드 (지속일수)

**기관 투자자**
- 기관 순매수/순매도
- 기관별 매매 현황 (연기금, 투신, 보험 등)
- 기관 매매 트렌드

**개인 투자자**
- 개인 순매수/순매도
- 투자 주체 간 수급 균형

**데이터 구조:**
```python
investor_analysis = {
    # 분석 기간
    "analysis_start_date": "2019-08-20",  # 2번 블록 D일
    "block_end_date": "2019-10-15",       # 2번 블록 종료일 (60이평선 회귀)
    "current_date": "2020-03-15",         # 분석 현재 시점
    "total_analysis_days": 208,           # 총 분석 일수 (2번 블록 D일 ~ 현재)

    # 외국인 투자자
    "foreign_investor": {
        "net_buy_value": 25000000000,          # 순매수 금액 (원)
        "net_buy_shares": 500000,              # 순매수 주식수
        "ownership_change": 2.5,               # 보유 비중 변화 (%)
        "ownership_start": 15.2,               # 기간 시작 시 보유 비중 (%)
        "ownership_end": 17.7,                 # 기간 종료 시 보유 비중 (%)
        "consecutive_buy_days": 35,            # 연속 순매수 일수
        "trend": "강한 매수",                   # 트렌드: "강한 매수/매수/중립/매도/강한 매도"
    },

    # 기관 투자자
    "institutional_investor": {
        "net_buy_value": 18000000000,          # 순매수 금액 (원)
        "net_buy_shares": 360000,              # 순매수 주식수
        "consecutive_buy_days": 28,            # 연속 순매수 일수
        "trend": "매수",                        # 트렌드

        # 기관별 상세
        "by_type": {
            "pension": 8000000000,             # 연기금
            "investment_trust": 6000000000,    # 투신
            "insurance": 4000000000,           # 보험
            "bank": -500000000,                # 은행 (순매도)
            "other": 500000000,                # 기타
        }
    },

    # 개인 투자자
    "individual_investor": {
        "net_buy_value": -43000000000,         # 순매도 금액 (원)
        "net_buy_shares": -860000,             # 순매도 주식수
        "consecutive_sell_days": 32,           # 연속 순매도 일수
        "trend": "강한 매도",                   # 트렌드
    },

    # 수급 균형 분석
    "supply_demand_balance": {
        "foreign_trend": "순매수",             # 외국인 순매수 추세: "순매수" or "순매도" or "중립"
        "institutional_trend": "순매수",       # 기관 순매수 추세: "순매수" or "순매도" or "중립"
        "individual_trend": "순매도",          # 개인 순매수 추세: "순매수" or "순매도" or "중립"

        "dominance": "외국인+기관",             # 주도 세력: "외국인" or "기관" or "개인" or "외국인+기관"
        "foreign_institutional_sync": True,    # 외국인-기관 동조화 여부
        "individual_resistance": "강함",       # 개인 저항 강도: "강함" or "보통" or "약함"
        "balance_score": 8.5,                  # 수급 균형 점수 (10점 만점)
        "interpretation": "외국인+기관 강한 매수 vs 개인 매도 → 긍정적 수급"
    }
}
```

---

## 2.4 산업 트렌드 분석

> **분석 기준 기간**: 1번 거래량 블록 D일 기준 2년 전부터 분석 현재 시점까지 지속적으로 분석

### 2.4.1 시장 및 대중 관심도

**검색 트렌드**
- 네이버/구글 검색량 분석
- 뉴스 언급 빈도
- 소셜미디어 (트위터, 주식 커뮤니티) 관심도

**미디어 노출도**
- 뉴스 기사 수 및 감성 분석
- 언론 보도 톤 (긍정/부정/중립)
- 애널리스트 리포트 발행 빈도

**데이터 구조:**
```python
market_interest_analysis = {
    # 분석 기간
    "analysis_start_date": "2017-03-15",  # 1번 블록 D일 - 2년
    "primary_block_date": "2019-03-15",   # 1번 블록 D일
    "secondary_block_date": "2019-08-20", # 2번 블록 D일
    "current_date": "2020-03-15",         # 분석 현재 시점
    "total_analysis_days": 1096,          # 총 분석 일수 (2년 전 ~ 현재)

    # 검색 트렌드
    "search_trends": {
        "naver_search_volume": 85000,          # 네이버 검색량 (기간 합계)
        "google_search_volume": 12000,         # 구글 검색량 (기간 합계)
        "search_increase_rate": 450.5,         # 전월 대비 검색량 증가율 (%)
        "peak_search_date": "2019-09-10",      # 검색량 최고 날짜
        "news_mention_count": 125,             # 뉴스 언급 횟수
        "social_media_mentions": 8500,         # 소셜미디어 언급
        "trend_score": 9.2,                    # 관심도 점수 (10점 만점)
    },

    # 미디어 노출도
    "media_exposure": {
        "news_count": 125,                     # 뉴스 기사 수
        "positive_ratio": 65.5,                # 긍정 비율 (%)
        "negative_ratio": 8.2,                 # 부정 비율 (%)
        "neutral_ratio": 26.3,                 # 중립 비율 (%)
        "media_tone": "긍정",                   # 전반적 보도 톤
        "analyst_reports": 8,                  # 애널리스트 리포트 수
        "avg_target_price": 75000,             # 평균 목표가
        "upgrade_count": 5,                    # 투자의견 상향 건수
        "downgrade_count": 0,                  # 투자의견 하향 건수
        "exposure_score": 8.8,                 # 미디어 노출 점수 (10점 만점)
    }
}
```

### 2.4.2 산업 사이클 변화

**산업 내 위치**
- 해당 산업의 성장 단계 분석
- 산업 트렌드 변화의 선도 여부
- 경쟁사 대비 시장 점유율 변화

**산업 사이클**
- 산업별 경기 사이클 단계 (도입/성장/성숙/쇠퇴)
- 신기술/신제품 출시 사이클
- 규제 변화 및 정책 지원

**데이터 구조:**
```python
industry_cycle_analysis = {
    # 분석 기간
    "analysis_start_date": "2017-03-15",  # 1번 블록 D일 - 2년
    "primary_block_date": "2019-03-15",   # 1번 블록 D일
    "secondary_block_date": "2019-08-20", # 2번 블록 D일
    "current_date": "2020-03-15",         # 분석 현재 시점

    # 산업 내 위치
    "industry_position": {
        "industry_name": "2차전지",            # 산업명
        "growth_stage": "성장기",              # 도입/성장/성숙/쇠퇴
        "is_trend_leader": True,              # 산업 트렌드 선도 여부
        "market_share": 18.5,                 # 시장 점유율 (%)
        "market_share_change_1y": 5.2,        # 1년 전 대비 점유율 변화 (%)
        "market_rank": 2,                     # 업계 순위
        "rank_change_1y": 1,                  # 1년 전 대비 순위 변화 (상승: +)
    },

    # 산업 사이클
    "industry_cycle": {
        "cycle_stage": "성장기",               # 사이클 단계
        "industry_growth_rate": 35.5,         # 산업 성장률 (%)
        "new_product_launch": True,           # 신제품 출시 여부
        "new_technology": True,               # 신기술 도입 여부
        "regulatory_change": "지원 확대",      # 규제 변화: "지원 확대/중립/규제 강화"
        "government_support": True,           # 정부 정책 지원 여부
        "cycle_score": 9.5,                   # 산업 사이클 점수 (10점 만점)
    }
}
```

### 2.4.3 섹터/테마 주도주 분석

> **핵심 목적**: 해당 종목이 속한 섹터/테마에서 주도주(Leading Stock)인지 파악
> **중요성**: 주도주는 섹터 상승 시 가장 먼저, 가장 크게 상승하며, 하락 시 방어력도 강함

#### 주도주 판단 기준

**1) 상대 강도 분석 (Relative Strength)**
- 섹터/테마 내 다른 종목 대비 수익률 비교
- 섹터 지수 대비 초과 수익률
- 선행 상승 여부 (섹터 랠리 시작 시점보다 먼저 상승)

**2) 거래량 우위**
- 섹터 내 거래대금 순위
- 섹터 평균 대비 거래량 배율
- 거래량 증가 타이밍 (섹터 내 가장 먼저 증가)

**3) 시가총액 및 유동성**
- 섹터 내 시가총액 순위
- 기관/외국인 보유 비중
- 일평균 거래대금 (유동성)

**4) 뉴스/이슈 주도성**
- 섹터 대표 종목으로 언론 보도
- 애널리스트 리포트 발행 빈도
- 섹터 관련 뉴스 시 가장 먼저 언급

**데이터 구조:**
```python
sector_theme_leadership_analysis = {
    # 분석 기간
    "analysis_start_date": "2017-03-15",  # 1번 블록 D일 - 2년
    "primary_block_date": "2019-03-15",   # 1번 블록 D일
    "secondary_block_date": "2019-08-20", # 2번 블록 D일
    "current_date": "2020-03-15",         # 분석 현재 시점

    # 섹터/테마 분류
    "sector_theme": {
        "primary_sector": "2차전지",              # 주 섹터
        "sub_sectors": ["양극재", "전해액"],      # 세부 섹터
        "themes": [                               # 속한 테마 (복수 가능)
            "전기차",
            "그린뉴딜",
            "ESG"
        ],
        "sector_index": "KRX 2차전지 지수",       # 관련 섹터 지수
    },

    # 주도주 종합 점수
    "leadership_score": 9.2,                      # 주도주 점수 (0~10점)
    "leadership_grade": "A",                      # 주도주 등급 (S/A/B/C/D)

    # 1) 상대 강도 분석
    "relative_strength": {
        # 수익률 비교 (1번 블록 고점 기준 상승률)
        "return_1m": 45.5,                        # 1번 블록 고점 이후 1개월 상승률 (%)
        "sector_avg_return_1m": 22.3,             # 섹터 평균 1개월 상승률 (%)
        "outperformance_1m": 23.2,                # 초과 수익률 (%)

        "return_3m": 125.8,                       # 1번 블록 고점 이후 3개월 상승률 (%)
        "sector_avg_return_3m": 68.5,             # 섹터 평균 3개월 상승률 (%)
        "outperformance_3m": 57.3,                # 초과 수익률 (%)

        "return_6m": 285.5,                       # 1번 블록 고점 이후 6개월 상승률 (%)
        "sector_avg_return_6m": 142.3,            # 섹터 평균 6개월 상승률 (%)
        "outperformance_6m": 143.2,               # 초과 수익률 (%)

        # 섹터 지수 대비
        "vs_sector_index_1m": 18.5,               # 섹터 지수 대비 초과 수익률 1개월 (%)
        "vs_sector_index_3m": 45.2,               # 섹터 지수 대비 초과 수익률 3개월 (%)
        "vs_sector_index_6m": 98.7,               # 섹터 지수 대비 초과 수익률 6개월 (%)

        # 시장 지수 대비 (KOSPI/KOSDAQ)
        "market_index": "KOSDAQ",                 # 소속 시장 (KOSPI/KOSDAQ)
        "vs_kospi_1m": 35.2,                      # KOSPI 대비 초과 수익률 1개월 (%)
        "vs_kospi_3m": 88.5,                      # KOSPI 대비 초과 수익률 3개월 (%)
        "vs_kospi_6m": 215.8,                     # KOSPI 대비 초과 수익률 6개월 (%)
        "vs_kosdaq_1m": 28.7,                     # KOSDAQ 대비 초과 수익률 1개월 (%)
        "vs_kosdaq_3m": 75.3,                     # KOSDAQ 대비 초과 수익률 3개월 (%)
        "vs_kosdaq_6m": 195.2,                    # KOSDAQ 대비 초과 수익률 6개월 (%)

        # 섹터의 시장 지수 대비 상승률
        "sector_vs_kospi_1m": 12.5,               # 섹터 지수의 KOSPI 대비 1개월 초과 수익률 (%)
        "sector_vs_kospi_3m": 35.8,               # 섹터 지수의 KOSPI 대비 3개월 초과 수익률 (%)
        "sector_vs_kospi_6m": 85.5,               # 섹터 지수의 KOSPI 대비 6개월 초과 수익률 (%)
        "sector_vs_kosdaq_1m": 8.2,               # 섹터 지수의 KOSDAQ 대비 1개월 초과 수익률 (%)
        "sector_vs_kosdaq_3m": 28.5,              # 섹터 지수의 KOSDAQ 대비 3개월 초과 수익률 (%)
        "sector_vs_kosdaq_6m": 72.3,              # 섹터 지수의 KOSDAQ 대비 6개월 초과 수익률 (%)

        # 선행성
        "is_early_mover": True,                   # 섹터 랠리 선행 여부
        "sector_rally_start_date": "2019-02-20",  # 섹터 랠리 시작일
        "stock_rally_start_date": "2019-02-10",   # 해당 종목 상승 시작일
        "lead_days": 10,                          # 선행 일수 (양수: 선행, 음수: 후행)

        # 상대 강도 점수
        "relative_strength_rank": 2,              # 섹터 내 상대 강도 순위
        "total_stocks_in_sector": 45,             # 섹터 내 총 종목 수
        "relative_strength_percentile": 95.6,     # 상대 강도 백분위 (%)
        "rs_score": 9.5,                          # 상대 강도 점수 (10점 만점)
    },

    # 2) 거래량 우위
    "volume_dominance": {
        # 거래대금
        "avg_daily_trading_value": 250000000000,  # 일평균 거래대금 (원)
        "sector_avg_trading_value": 85000000000,  # 섹터 평균 거래대금 (원)
        "trading_value_rank": 1,                  # 섹터 내 거래대금 순위
        "trading_value_ratio": 2.94,              # 섹터 평균 대비 배율

        # 거래량 증가
        "volume_increase_rate": 850.5,            # 전월 대비 거래량 증가율 (%)
        "sector_avg_volume_increase": 320.2,      # 섹터 평균 거래량 증가율 (%)
        "volume_increase_rank": 1,                # 섹터 내 거래량 증가율 순위

        # 거래량 타이밍
        "volume_surge_date": "2019-02-08",        # 거래량 급증 시작일
        "sector_volume_surge_date": "2019-02-18", # 섹터 평균 거래량 급증일
        "volume_lead_days": 10,                   # 거래량 선행 일수
        "is_volume_leader": True,                 # 거래량 선행 여부

        "volume_score": 9.8,                      # 거래량 우위 점수 (10점 만점)
    },

    # 3) 시가총액 및 수급
    "market_cap_supply": {
        # 시가총액
        "market_cap": 15000000000000,             # 시가총액 (원)
        "market_cap_rank": 1,                     # 섹터 내 시총 순위
        "market_cap_share": 22.5,                 # 섹터 내 시총 비중 (%)

        # 1번 거래량 블록 D일 수급
        "block_1_d_institutional_buy": 5000000000,    # 1번 블록 D일 기관 매수 금액 (원)
        "block_1_d_foreign_buy": 8000000000,          # 1번 블록 D일 외국인 매수 금액 (원)
        "block_1_d_is_institutional_buying": True,    # 1번 블록 D일 기관 순매수 여부
        "block_1_d_is_foreign_buying": True,          # 1번 블록 D일 외국인 순매수 여부

        # 2번 거래량 블록 D일 수급
        "block_2_d_institutional_buy": 12000000000,   # 2번 블록 D일 기관 매수 금액 (원)
        "block_2_d_foreign_buy": 15000000000,         # 2번 블록 D일 외국인 매수 금액 (원)
        "block_2_d_is_institutional_buying": True,    # 2번 블록 D일 기관 순매수 여부
        "block_2_d_is_foreign_buying": True,          # 2번 블록 D일 외국인 순매수 여부

        # 2번 거래량 블록 D+1일 수급
        "block_2_d1_institutional_buy": 8000000000,   # 2번 블록 D+1일 기관 매수 금액 (원)
        "block_2_d1_foreign_buy": 10000000000,        # 2번 블록 D+1일 외국인 매수 금액 (원)
        "block_2_d1_is_institutional_buying": True,   # 2번 블록 D+1일 기관 순매수 여부
        "block_2_d1_is_foreign_buying": True,         # 2번 블록 D+1일 외국인 순매수 여부

        # 2번 거래량 블록 D+2일 수급
        "block_2_d2_institutional_buy": 6000000000,   # 2번 블록 D+2일 기관 매수 금액 (원)
        "block_2_d2_foreign_buy": 7000000000,         # 2번 블록 D+2일 외국인 매수 금액 (원)
        "block_2_d2_is_institutional_buying": True,   # 2번 블록 D+2일 기관 순매수 여부
        "block_2_d2_is_foreign_buying": True,         # 2번 블록 D+2일 외국인 순매수 여부

        # 유동성
        "avg_daily_turnover_ratio": 8.5,          # 일평균 회전율 (%)
        "liquidity_rank": 1,                      # 섹터 내 유동성 순위
        "is_highly_liquid": True,                 # 고유동성 여부 (일 거래대금 500억 이상)

        "supply_score": 9.2,                      # 수급 점수 (10점 만점)
    },

    # 4) 뉴스/이슈 주도성
    "news_leadership": {
        # 언론 보도
        "news_mention_count": 285,                # 뉴스 언급 횟수 (기간 내)
        "sector_avg_news_count": 85,              # 섹터 평균 뉴스 횟수
        "news_mention_rank": 1,                   # 섹터 내 뉴스 언급 순위

        # 섹터 대표성
        "is_sector_representative": True,         # 섹터 대표 종목 여부
        "sector_news_mention_ratio": 45.5,        # 섹터 관련 뉴스 중 언급 비율 (%)

        # 애널리스트 커버리지
        "analyst_coverage": 18,                   # 커버리지 애널리스트 수
        "sector_avg_coverage": 6,                 # 섹터 평균 커버리지
        "analyst_reports_1y": 52,                 # 1년간 리포트 발행 건수
        "target_price_consensus": 95000,          # 컨센서스 목표가
        "buy_rating_ratio": 85.5,                 # 매수 의견 비율 (%)

        # 검색 트렌드
        "search_volume": 125000,                  # 검색량 (기간 합계)
        "sector_avg_search": 38000,               # 섹터 평균 검색량
        "search_rank": 1,                         # 섹터 내 검색량 순위

        "media_leadership_score": 9.5,            # 언론 주도성 점수 (10점 만점)
    },

    # 주도주 패턴 분석
    "leadership_pattern": {
        # 주도주 전환 시점
        "became_leader_date": "2019-01-15",       # 주도주 전환 시점
        "leadership_duration_days": 420,          # 주도주 지속 기간 (일)
        "is_consistent_leader": True,             # 지속적 주도주 여부 (3개월 이상)

        # 섹터 랠리 주도
        "led_sector_rally": True,                 # 섹터 랠리 주도 여부
        "sector_rally_correlation": 0.92,         # 섹터 지수와 상관계수
        "leads_sector_index": True,               # 섹터 지수 선행 여부

        # 경쟁 주도주
        "competing_leaders": [                    # 경쟁 주도주 종목
            {"name": "LG화학", "leadership_score": 8.8},
            {"name": "삼성SDI", "leadership_score": 8.5},
        ],
        "leadership_advantage": 0.4,              # 2위 대비 점수 차이
    }
}
```

#### 주도주 등급 산정

```python
# 주도주 등급 계산
def calculate_leadership_grade(analysis):
    # 4가지 영역 점수 평균
    scores = [
        analysis['relative_strength']['rs_score'],        # 상대 강도
        analysis['volume_dominance']['volume_score'],     # 거래량 우위
        analysis['market_cap_supply']['supply_score'],    # 수급
        analysis['news_leadership']['media_leadership_score']  # 언론 주도성
    ]

    leadership_score = sum(scores) / len(scores)

    # 등급 부여
    if leadership_score >= 9.0:
        grade = "S"  # 확실한 주도주 (섹터 대장주)
    elif leadership_score >= 8.0:
        grade = "A"  # 강력한 주도주
    elif leadership_score >= 7.0:
        grade = "B"  # 준 주도주
    elif leadership_score >= 6.0:
        grade = "C"  # 중위권 종목
    else:
        grade = "D"  # 비주도주 (팔로워)

    return leadership_score, grade

# 주도주 판단 기준
# - S등급 (9.0+): 확실한 섹터 대장주
# - A등급 (8.0~9.0): 강력한 주도주
# - B등급 (7.0~8.0): 준 주도주
# - C등급 (6.0~7.0): 중위권 종목
# - D등급 (6.0 미만): 비주도주 (팔로워)
```

#### 시각화 예시

```
[섹터 내 상대 강도 비교]
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
종목명          6개월 수익률    섹터 대비    주도성
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
LG에너지솔루션   +285.5%       +143.2%      ★ 주도주
삼성SDI         +195.3%        +53.0%      준주도주
LG화학          +178.8%        +36.5%      준주도주
포스코케미칼     +142.3%         +0.0%      평균
에코프로         +98.5%        -43.8%      후행주
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[거래대금 순위]
1. LG에너지솔루션  2,500억 (섹터 평균의 2.94배) ★
2. 삼성SDI        1,850억 (섹터 평균의 2.18배)
3. LG화학         1,620억 (섹터 평균의 1.91배)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[시계열 주도성 분석]
2019-02-10 ▶ LG에너지솔루션 상승 시작 (+10% 급등)
2019-02-18 ▶ 섹터 평균 상승 시작 (8일 선행) ✓
2019-02-20 ▶ 섹터 지수 상승 전환 (10일 선행) ✓
→ 주도주 확정: 선행 상승 + 섹터 견인
```

### 2.4.4 미래 산업 포함 여부

**미래 성장 산업 분류**
- AI/빅데이터
- 전기차/2차전지
- 바이오/헬스케어
- 반도체/첨단소재
- 신재생에너지
- 로봇/자동화
- 메타버스/콘텐츠

**기술 혁신성**
- R&D 투자 비중
- 특허 출원 및 등록 현황
- 신제품/신기술 개발 파이프라인

**정부 정책 부합도**
- 국가 전략 산업 포함 여부
- 정부 지원금/보조금 수혜
- 규제 완화 혜택

**데이터 구조:**
```python
future_industry_analysis = {
    # 분석 기간
    "analysis_start_date": "2017-03-15",  # 1번 블록 D일 - 2년
    "primary_block_date": "2019-03-15",   # 1번 블록 D일
    "secondary_block_date": "2019-08-20", # 2번 블록 D일
    "current_date": "2020-03-15",         # 분석 현재 시점

    # 미래 성장 산업 분류
    "future_industry": {
        "is_future_industry": True,           # 미래 성장 산업 여부
        "categories": [                       # 해당 분야 (복수 가능)
            "전기차/2차전지",
            "신재생에너지"
        ],
        "primary_category": "전기차/2차전지",  # 주력 분야
        "future_industry_score": 9.0,         # 미래 산업 점수 (10점 만점)
    },

    # 기술 혁신성
    "technology_innovation": {
        "rnd_ratio": 8.5,                     # R&D 투자 비중 (매출 대비 %)
        "rnd_investment": 50000000000,        # R&D 투자액 (원, 연간)
        "patent_applications_1y": 85,         # 1년간 특허 출원 건수
        "patent_registrations_1y": 42,        # 1년간 특허 등록 건수
        "new_product_pipeline": 5,            # 신제품 개발 파이프라인 (개)
        "new_technology_pipeline": 3,         # 신기술 개발 파이프라인 (개)
        "innovation_score": 8.2,              # 기술 혁신성 점수 (10점 만점)
    },

    # 정부 정책 부합도
    "government_policy": {
        "is_national_strategy": True,         # 국가 전략 산업 포함 여부
        "subsidy_received_1y": 8000000000,    # 1년간 정부 지원금/보조금 (원)
        "regulatory_benefits": [              # 규제 완화 혜택
            "세액 공제",
            "R&D 지원",
            "저리 융자"
        ],
        "policy_alignment_score": 9.5,        # 정책 부합도 점수 (10점 만점)
    },

    # 종합 평가
    "overall_assessment": {
        "total_score": 8.9,                   # 종합 점수 (10점 만점)
        "grade": "A+",                        # 등급 (S/A+/A/B+/B/C/D)
        "interpretation": "미래 성장 산업 + 높은 기술 혁신성 + 정부 강력 지원 → 최상급 성장 잠재력"
    }
}
```

---

## 3. 개발 방향

### 3.1 데이터 수집

- **대상 기간**: 2015년 ~ 2025년 (10년)
- **시장**: KOSPI, KOSDAQ 전체 종목
- **목표**: 1번 거래량 블록 + 2번 거래량 블록을 모두 만족하는 케이스 수집

#### 3.1.1 데이터 소스

**주가/거래 데이터 (pykrx - 추천)**
```python
pip install pykrx
from pykrx import stock

# OHLCV + 거래대금
df = stock.get_market_ohlcv("20150101", "20250101", "005930")

# 투자자별 매매 동향 (개인/외국인/기관)
investor = stock.get_market_trading_value_by_investor("20250101", "20250131", "005930")

# 공매도 잔고
short = stock.get_shorting_balance_by_date("20250101", "20250131", "005930")

# 프로그램 매매
program = stock.get_market_trading_value_by_date("20250101", "20250131", "005930")

# 전체 종목 리스트
kospi_list = stock.get_market_ticker_list("20250101", market="KOSPI")
kosdaq_list = stock.get_market_ticker_list("20250101", market="KOSDAQ")
```
- **제공 데이터**: OHLCV, 거래량, 거래대금, 투자자별 매매, 공매도, 프로그램 매매
- **장점**: 무료, 한국거래소 공식 데이터, API 제한 없음
- **기간**: 2000년대 초반부터 현재까지

**재무제표 데이터 (dart-fss)**
```python
pip install dart-fss
import dart_fss as dart

# API KEY 발급 (무료): https://opendart.fss.or.kr/
dart.set_api_key('YOUR_API_KEY')

# 재무제표 조회
corp = dart.Corporation('005930')  # 삼성전자
fs = corp.get_financial_statement()

# 주요 재무 지표
# - 매출액, 영업이익, 순이익
# - 자본총계, 부채총계, 부채비율
# - ROE, ROA
# - 이익잉여금
```
- **제공 데이터**: 전체 재무제표 (분기별/연도별)
- **장점**: 무료, 금융감독원 공식 데이터
- **기간**: 상장 이후 전체 기간

**검색/뉴스 데이터**
```python
# Google Trends
pip install pytrends
from pytrends.request import TrendReq

pytrends = TrendReq(hl='ko', tz=540)
pytrends.build_payload(['삼성전자'], timeframe='2015-01-01 2025-01-01')
trends = pytrends.interest_over_time()

# 네이버 뉴스 API (API 키 발급 필요)
# https://developers.naver.com/products/service-api/search/search.md
```

**거시경제 지표 (FinanceDataReader)**
```python
pip install finance-datareader
import FinanceDataReader as fdr

# 환율 (USD/KRW)
usd_krw = fdr.DataReader('USD/KRW', '2015-01-01')

# 유가 (WTI)
oil = fdr.DataReader('WTI', '2015-01-01')

# 금리 데이터는 한국은행 API 활용
```

**산업 분류**
```python
# pykrx로 업종 분류 조회
from pykrx import stock

# 종목의 업종 정보
ticker_name = stock.get_market_ticker_name("005930")
```

**데이터 수집 범위:**
- **기간**: 2015년 ~ 2025년 (10년)
- **시장**: KOSPI, KOSDAQ 전체 종목
- **빈도**: 일별 (OHLCV, 거래량), 분기별 (재무제표)

**데이터 수집 시점 정의:**
> **중요**: 각 분석 항목별로 수집 시점이 다름

| 분석 항목 | 수집 시작 시점 | 수집 종료 시점 | 설명 |
|----------|-------------|-------------|------|
| **거래량 블록 탐지** | 2년 전 | 1번/2번 블록 발생일 | 2년래 최대 거래량 판단 위해 |
| **당일 수급 (스냅샷)** | 1번 D일, 2번 D/D+1/D+2일 | 해당 당일 | 각 날짜의 순매수/순매도만 |
| **재무제표 트렌드** | 1번 블록 D일 - 2년 | 분석 현재 시점 | 2년간 재무 추세 분석 |
| **수급 트렌드** | 2번 블록 D일 | 분석 현재 시점 | 기간 매매 추세 분석 |
| **산업 트렌드** | 1번 블록 D일 - 2년 | 분석 현재 시점 | 검색량, 뉴스, 관심도 추세 |
| **장기 가격 흐름** | 2번 블록 고점 | +5년 | 라벨링용 수익률 추적 |

#### 3.1.2 수집 데이터 구조

**1번 거래량 블록 데이터**
- **기본 정보**
  - D일 날짜 및 OHLCV
  - 거래대금 및 점수 (500억원 기준)
  - 2년래 최대 거래량 여부
- **D일 당일 수급 데이터 (스냅샷)**
  - 기관/외국인/외국인+기관/개인 순매수 금액
  - 각 주체별 순매수 여부 (Boolean)
- **신고가 분석**
  - 2년래 신고가 여부
  - 2년 내 최고가
- **블록 범위 데이터**
  - 1번 D일 ~ 2번 D일 전날까지
  - 블록 기간 최고가/최저가
  - 평균 일 거래량

**2번 거래량 블록 데이터**
- **기본 정보**
  - 1번 블록 발생일로부터 경과 일수 (6개월 내)
  - D, D+1, D+2 일자 및 각각의 OHLCV
  - 1번 블록 대비 거래량 비율 (80% 이상)
- **D, D+1, D+2 당일 수급 데이터 (스냅샷)**
  - 각 날짜별 기관/외국인/외국인+기관/개인 순매수 금액
  - 각 주체별 순매수 여부 (Boolean)
- **패턴 매칭**
  - D+D+1, D+D+2, D+D+1+D+2 패턴 만족 여부
  - 매칭된 패턴명
- **거래대금 조건**
  - D, D+1, D+2 중 2000억원 이상 여부
- **14일 이상 고가 위 종가 형성 기간**
- **블록 범위 데이터 (60일 이동평균선 기준)**
  - 2번 D일 ~ 60이평선 회귀일
  - 블록 기간 최고가 (★ 수익률 기준점)
  - 60이평선 터치/하방이탈 여부
- **신고가 분석**
  - 2년/5년/10년/역사적 신고가 여부
  - 각 기간별 최고가 및 달성일
  - 신고가 등급 (S/A/B/C/D/E/F)

**재무제표 트렌드 데이터**
- **수집 기간**: 1번 블록 D일 기준 2년 전 ~ 분석 현재 시점
- **영업이익 트렌드**
  - 분기별 영업이익, 영업이익률
  - 적자→흑자 전환 시점
  - 연속 증가 분기 수
  - ROE, ROA 추이
  - 컨센서스 대비 실적 서프라이즈
- **자본 총계 트렌드**
  - 분기별 자본 총계 증가율
  - 연속 증가 분기 수
  - 이익잉여금 누적 추이
  - 부채비율 변화

**수급 트렌드 데이터 (기간 분석)**
- **수집 기간**: 2번 블록 D일 ~ 분석 현재 시점
- **외국인 투자자**
  - 순매수 금액 및 주식수
  - 보유 비중 변화
  - 연속 순매수/순매도 일수
  - 매매 트렌드 강도
- **기관 투자자**
  - 순매수 금액 및 주식수
  - 기관별 매매 현황 (연기금/투신/보험 등)
  - 연속 순매수/순매도 일수
- **개인 투자자**
  - 순매수 금액 및 주식수
  - 연속 순매수/순매도 일수
- **수급 균형 분석**
  - 외국인/기관/개인 각 추세
  - 주도 세력
  - 수급 균형 점수
- **공매도/프로그램 매매**
  - 공매도 비중 및 잔고 변화
  - 프로그램 순매수/순매도

**산업 트렌드 데이터**
- **수집 기간**: 1번 블록 D일 기준 2년 전 ~ 분석 현재 시점
- **시장 및 대중 관심도**
  - 네이버/구글 검색량
  - 뉴스 기사 수 및 감성 분석
  - 애널리스트 리포트 수
- **산업 사이클 변화**
  - 산업 성장 단계
  - 시장 점유율 변화
  - 신기술/신제품 출시 여부
- **미래 산업 포함 여부**
  - 미래 성장 산업 분류 (AI/2차전지/바이오 등)
  - R&D 투자 비중
  - 특허 출원/등록 현황
  - 정부 지원금/보조금 수혜

**장기 가격 흐름 데이터 (라벨링용)**
- **기준일**: 2번 거래량 블록 고점 (D, D+1, D+2 중 최고가)
- **추적 기간**: 최대 5년
- **수집 데이터**:
  - **수익률 추적**
    - 6개월, 1년, 2년, 3년, 5년 시점 수익률
    - 최고가 도달 시점 및 수익률
    - 수익률 구간 분류 (Level 0~4: 실패~초고수익)
  - **기간 분석**
    - 50% 도달까지 소요 일수 (days_to_50pct)
    - 100% 도달까지 소요 일수 (days_to_100pct)
    - 최고 수익률 도달 일수 (days_to_peak)
    - 기간 구간 분류 (초단기/단기/중기/장기/미달성)
  - **최대 낙폭(MDD) 분석**
    - 2번 블록 고점 대비 최대 하락률 (mdd_from_block_high)
    - MDD 발생일 (mdd_date)
    - MDD까지 소요 일수 (days_to_mdd)
    - MDD 심각도 (경미/보통/심각/매우심각)
  - **실패 케이스 상세 분석** (Level 0인 경우)
    - 5년 후 최종 수익률 (final_return_5y)
    - 지속 하락 여부 (is_continuous_decline)
    - 5년 중 최고 수익률 (max_return_during_5y)
    - 최고점 이후 하락폭 (decline_after_peak)
    - 블록 고점 아래 머문 일수 (below_block_high_days)
    - 실패 패턴 유형 (실패-지속하락/실패-횡보 등)
  - **리스크-수익 프로파일**
    - 리스크-수익 비율 (max_return / |MDD|)
    - 주요 가격 변곡점 (고점, 저점)

### 3.2 데이터 전처리

**기본 전처리**
- 결측치 처리
- 이상치 탐지 및 제거
- 데이터 정규화/표준화
- 주식 분할, 배당 등 조정
- 시계열 데이터 정렬 및 동기화

**거래량 블록 탐지 알고리즘**
```python
# 1번 거래량 블록 탐지
def detect_primary_volume_block(df, date):
    """
    Args:
        df: 주가 데이터 (최소 2년치)
        date: 검사할 날짜
    Returns:
        is_primary_block: Boolean
        block_info: dict
    """
    # 1. 2년래 최대 거래량 확인
    two_years_ago = date - timedelta(days=730)
    volume_2y = df.loc[two_years_ago:date, 'volume']
    is_2y_max = df.loc[date, 'volume'] == volume_2y.max()

    # 2. 거래대금 500억원 이상 확인
    trading_value = df.loc[date, 'close'] * df.loc[date, 'volume'] / 100000000
    is_500b_value = trading_value >= 500

    # 3. D일 수급 데이터 수집
    investor_data = get_investor_trading(date)  # pykrx 사용

    return is_2y_max and is_500b_value, {
        'd_volume': df.loc[date, 'volume'],
        'd_trading_value': trading_value,
        'd_institutional_net_buy': investor_data['institutional'],
        'd_foreign_net_buy': investor_data['foreign'],
        # ...
    }

# 2번 거래량 블록 탐지
def detect_secondary_volume_block(df, primary_date, candidate_date):
    """
    Args:
        df: 주가 데이터
        primary_date: 1번 블록 D일
        candidate_date: 2번 블록 후보 날짜
    Returns:
        is_secondary_block: Boolean
        pattern_matched: str
    """
    # 1. 6개월 내 발생 확인
    days_diff = (candidate_date - primary_date).days
    if days_diff > 180:
        return False, None

    # 2. 1번 블록 대비 80% 이상 거래량
    primary_volume = df.loc[primary_date, 'volume']
    d_volume = df.loc[candidate_date, 'volume']
    if d_volume < primary_volume * 0.8:
        return False, None

    # 3. D+1, D+2 패턴 검증
    d1_date = candidate_date + timedelta(days=1)
    d2_date = candidate_date + timedelta(days=2)

    pattern = check_pattern(df, candidate_date, d1_date, d2_date, d_volume)

    # 4. 필수 조건 4가지 검증
    if not check_4_conditions(df, primary_date, candidate_date, d1_date, d2_date):
        return False, None

    return True, pattern

def check_pattern(df, d_date, d1_date, d2_date, d_volume):
    """D+D+1, D+D+2, D+D+1+D+2 패턴 확인"""
    d1_qualified = (
        df.loc[d1_date, 'volume'] >= d_volume * 0.5 and
        df.loc[d1_date, 'high'] > df.loc[d_date, 'high']
    )
    d2_qualified = (
        df.loc[d2_date, 'volume'] >= d_volume * 0.5 and
        df.loc[d2_date, 'high'] > df.loc[d_date, 'high']
    )

    if d1_qualified and d2_qualified:
        return "D+D+1+D+2"
    elif d1_qualified:
        return "D+D+1"
    elif d2_qualified:
        return "D+D+2"
    else:
        return None
```

**60일 이동평균선 기반 블록 범위 탐지**
```python
def detect_block_end_by_ma60(df, block_start_date):
    """
    60일 이동평균선 터치/하방이탈로 블록 종료 탐지
    """
    # 60일 이동평균선 계산
    df['ma60'] = df['close'].rolling(window=60).mean()

    # 블록 시작일 이후 데이터
    after_start = df.loc[block_start_date:]

    # 60이평선 터치 또는 하방이탈 찾기
    for date, row in after_start.iterrows():
        # 터치: 저가가 60이평선 이하
        if row['low'] <= row['ma60']:
            return date, "터치"
        # 하방이탈: 종가가 60이평선 아래
        if row['close'] < row['ma60']:
            return date, "하방이탈"

    return None, None
```

**14일 이상 고가 위 종가 형성 검증**
```python
def check_14days_above_primary_high(df, primary_high, start_date, end_date):
    """
    2번 블록 D일 이후, 1번 블록 고가 위에서 14일 이상 종가 형성 확인
    """
    period = df.loc[start_date:end_date]
    above_high = period[period['close'] > primary_high]

    # 연속 14일 확인
    consecutive_days = 0
    max_consecutive = 0

    for date in period.index:
        if period.loc[date, 'close'] > primary_high:
            consecutive_days += 1
            max_consecutive = max(max_consecutive, consecutive_days)
        else:
            consecutive_days = 0

    return max_consecutive >= 14
```

**텍스트 데이터 전처리**
- 뉴스 기사 감성 분석 (긍정/부정/중립)
- 검색 트렌드 정규화
- 산업 키워드 매칭

### 3.3 모델 개발

> **중요**: 1.2 목표와 연결된 2단계 학습 전략

#### 3.3.1 비지도 학습 - 차별 팩터 발견

**목적**: 성공/실패 및 수익률 구간별(Level 0~4) 어떤 팩터가 차별화되는지 발견

**방법론**:

**Step 0: 탐색적 데이터 분석 (EDA)**
- **목적**: 데이터 전체 구조 파악 및 팩터 간 관계 이해
- **분석 방법**:
  - 기술 통계량 (평균, 중앙값, 표준편차, 분포)
  - 팩터 간 상관관계 분석
    - Pearson 상관계수 히트맵
    - Spearman 순위 상관계수 (비선형 관계)
  - 다중공선성 확인 (VIF, Variance Inflation Factor)
    - 신고가 등급과 외국인 순매수의 상관관계는?
    - 재무 턴어라운드와 미래 산업의 독립성은?
  - 팩터별 분포 시각화 (히스토그램, 박스플롯)
  - Level별 팩터 분포 비교
- **산출물**:
  - 상관관계 히트맵
  - VIF 스코어 (>10이면 다중공선성 의심)
  - 팩터별 분포 차트

**Step 1: 성공 vs 실패 팩터 분석 (Level 0 vs Level 1~4)**
- **목적**: 50% 이상 수익 발생 여부를 결정하는 핵심 팩터 발견
- **분석 방법**:
  - 전체 케이스를 Level 0(실패) vs Level 1~4(성공)로 2분류
  - Random Forest 분류 모델로 Feature Importance 추출
  - SHAP으로 성공/실패에 영향을 주는 팩터 순위화
  - 통계적 검정 (t-test, Mann-Whitney U test)으로 유의미한 차이 확인
- **주요 분석 질문**:
  - **수익 발생(50% 이상)에 결정적인 팩터는?**
    - 신고가 등급이 높을수록 성공률 증가?
    - 외국인+기관 순매수가 성공의 필수 조건?
    - 재무제표 턴어라운드가 필요한가?
    - 미래 산업 여부가 성공률에 영향?
  - 실패 케이스(Level 0)의 공통적인 약점은?
    - 낮은 신고가 등급? (D/E/F)
    - 개인 주도 수급?
    - 재무제표 악화?
    - 전통 산업?

**Step 1.5: 성공 케이스 내 Level별 차별 팩터 분석 (Level 1~4)**
- **목적**: 성공한 케이스 중에서도 Level 1 → 4로 갈수록 강화되는 팩터 발견
- **분석 방법**:
  - 성공 케이스(Level 1~4)만 필터링
  - K-means, DBSCAN, Hierarchical Clustering으로 그룹화
  - PCA, t-SNE, UMAP으로 Level 1~4 분포 시각화
  - Random Forest 회귀/다중분류로 Level 결정 팩터 추출
  - SHAP으로 고수익(Level 3~4) 달성 조건 분석
- **주요 분석 질문**:
  - **Level 1 → Level 4로 갈수록 강화되는 팩터는?**
    - 신고가 등급: C → A → S 순으로 Level 상승?
    - 외국인+기관 순매수 금액이 클수록?
    - 재무 개선 폭이 클수록? (영업이익률, 자본총계 증가율)
    - 미래 산업 점수가 높을수록?
    - 검색 트렌드/미디어 노출이 높을수록?
  - **초고수익(Level 4, 1000%+)의 특별한 조건은?**
    - 역사적 신고가(S등급) 필수?
    - 외국인+기관 동시 강한 매수?
    - 적자→흑자 턴어라운드 + 미래 산업?

**Step 2: 팩터 조합 시너지 분석**
- **목적**: 단일 팩터가 아닌 **팩터 조합의 시너지 효과** 발견
- **분석 방법**:
  - Association Rule Mining (Apriori, FP-Growth)
    - 빈번하게 함께 나타나는 팩터 조합 발견
    - Support, Confidence, Lift 계산
  - 2-way, 3-way 팩터 상호작용 분석
    - 신고가 S등급 + 외국인+기관 순매수 조합의 효과
    - 턴어라운드 + 미래 산업 조합의 시너지
  - Decision Tree로 팩터 조합 규칙 추출
- **주요 분석 질문**:
  - **2개 이상 팩터 동시 만족 시 성공률/수익률이 급상승하는가?**
    - 예: {신고가 A, 외국인 순매수, 미래산업} → Level 3+ (80% 확률)
    - 예: {신고가 S, 턴어라운드, 외국인+기관} → Level 4 (60% 확률)
  - **필수 조합**: 어떤 조합이 있어야 최소한 성공하는가?
  - **황금 조합**: Level 4 달성 확률이 가장 높은 조합은?
  - **독립 vs 시너지**: 팩터들이 독립적? 아니면 상승 작용?

**Step 3: 시간/리스크 팩터 분석**
- **클러스터링**
  - 수익률뿐 아니라 기간/MDD를 포함한 3차원 분석
  - "고수익-빠른 달성-낮은 MDD" vs "고수익-느린 달성-높은 MDD" 구분
- **주요 분석 질문**:
  - **수익 실현 기간**: 50% 도달까지 평균 며칠? Level별 차이는?
    - Level 4는 빠른가? 느린가?
    - 신고가 등급이 높으면 더 빠른가?
  - **최대 낙폭(MDD)**: 2번 블록 고점 대비 얼마나 하락? Level별 차이는?
    - Level 4도 높은 MDD를 겪는가?
    - 어떤 팩터가 MDD를 낮게 유지?
  - **리스크-수익 비율**: 고수익이면서 낮은 MDD인 케이스의 특징은?

**Step 4: 시계열 패턴 분석**
- **목적**: 단순 수치뿐 아니라 **시간에 따른 추세/패턴** 분석
- **분석 방법**:
  - DTW (Dynamic Time Warping)로 시계열 유사도 클러스터링
    - 재무제표 추세: 연속 증가 vs 등락 반복
    - 수급 추세: 지속적 순매수 vs 간헐적 순매수
    - 검색량 추세: 급증 vs 완만 증가
  - Shapelet 분석: 성공을 예측하는 특정 시계열 패턴 발견
  - Change Point Detection: 추세 전환 시점 탐지
- **주요 분석 질문**:
  - **재무제표 추세 패턴**:
    - 연속 4분기 증가 vs 2분기 증가 → 1분기 감소 → 다시 증가, 어느 쪽이 유리?
    - 급격한 개선 vs 완만한 개선의 차이는?
  - **수급 추세 패턴**:
    - 꾸준한 순매수 vs 폭발적 순매수 후 감소
    - 외국인-기관 교대 매수 vs 동시 매수
  - **검색량/미디어 노출 패턴**:
    - 2번 블록 전후로 급증하는가?
    - 지속적 관심 vs 일시적 관심

**Step 5: 세분화 분석 (Segmentation)**
- **목적**: 산업/시장/규모/주도성별로 성공 조건이 다른지 확인
- **분석 방법**:
  - 산업별 분석: 2차전지 vs 바이오 vs 반도체 vs 전통제조업
  - 시장별 분석: KOSPI vs KOSDAQ
  - 시가총액별 분석: 대형주(1조+) vs 중형주(1000억~1조) vs 소형주(<1000억)
  - **섹터/테마 주도성별 분석**: 주도주 vs 준주도주 vs 비주도주 ⭐ **핵심 추가**
  - 각 세그먼트별 독립적인 팩터 중요도 분석
- **주요 분석 질문**:
  - **산업별 차별 팩터**:
    - 2차전지: 미래 산업 점수가 필수?
    - 바이오: R&D 투자 비중이 중요?
    - 전통 제조업: 재무 턴어라운드가 더 중요?
  - **시장별 차이**:
    - KOSPI: 외국인 순매수가 더 중요?
    - KOSDAQ: 개인 관심도(검색량)가 더 중요?
  - **시가총액별 차이**:
    - 대형주: 안정적 성장, 낮은 MDD
    - 소형주: 폭발적 성장, 높은 MDD
  - **섹터/테마 주도성별 차이** ⭐ **핵심 추가**:
    - **주도주 (Leadership Grade S/A)**:
      - 성공 확률: ~85%
      - 평균 Level: 3.2 (고수익 구간)
      - 평균 MDD: -18% (낮은 리스크)
      - 핵심 팩터: 상대 강도(섹터 내 1-3위), 거래대금 우위, 언론 주도성
      - 투자 전략: 적극 투자, 섹터 랠리 시 우선 매수
    - **준주도주 (Leadership Grade B/C)**:
      - 성공 확률: ~65%
      - 평균 Level: 2.0 (중수익 구간)
      - 평균 MDD: -25% (중간 리스크)
      - 핵심 팩터: 재무 건전성, 수급 안정성
      - 투자 전략: 조건부 투자, 신고가 S/A 등급 시 선택
    - **비주도주/후행주 (Leadership Grade D)**:
      - 성공 확률: ~35%
      - 평균 Level: 1.2 (저수익 구간)
      - 평균 MDD: -35% (높은 리스크)
      - 핵심 팩터: 섹터 모멘텀에 의존, 독자 성장 동력 부족
      - 투자 전략: 회피 또는 초단타 (섹터 과열 시 이탈)
- **주도성별 성공률 차이 분석**:
  ```python
  # 주도주 여부에 따른 성공률
  leadership_analysis = data.groupby('leadership_grade').agg({
      'is_success': 'mean',
      'max_return_5y': 'mean',
      'mdd_from_block_high': 'mean',
      'return_level': 'mean'
  })

  # 예시 결과:
  # leadership_grade  is_success  max_return_5y  mdd_from_block_high  return_level
  # S (대장주)            0.92          520.5%            -15.2%           3.5
  # A (주도주)            0.85          385.2%            -18.8%           3.2
  # B (준주도주)          0.68          195.5%            -24.5%           2.1
  # C (중위권)            0.52          125.3%            -28.2%           1.6
  # D (후행주)            0.35           78.5%            -35.8%           1.0
  ```
- **주도주 + 다른 팩터 조합 효과**:
  ```python
  # 주도주 x 신고가 등급
  combo_analysis = data.groupby(['leadership_grade', 'new_high_grade']).agg({
      'is_success': 'mean',
      'return_level': 'mean'
  })

  # 예상 발견:
  # 주도주(S/A) + 신고가(S/A) → 성공률 95%, Level 3.8 (거의 확실한 성공)
  # 주도주(S/A) + 신고가(C/D) → 성공률 75%, Level 2.5 (신고가 약해도 성공 가능)
  # 비주도주(D) + 신고가(S/A) → 성공률 55%, Level 1.8 (주도성 없으면 제한적)
  # 비주도주(D) + 신고가(C/D) → 성공률 20%, Level 0.8 (높은 실패 확률)
  ```
- **섹터 랠리 타이밍 vs 주도성 분석**:
  ```python
  # 섹터 랠리 중 vs 비랠리 시 주도성 효과
  rally_leadership = data.groupby(['sector_rally_active', 'leadership_grade']).agg({
      'return_3m': 'mean',
      'return_6m': 'mean'
  })

  # 발견 예시:
  # 섹터 랠리 중 + 주도주(S/A) → 3개월 +85%, 6개월 +250% (폭발적 상승)
  # 섹터 랠리 중 + 비주도주(D) → 3개월 +35%, 6개월 +90% (따라가기만)
  # 비랠리 시 + 주도주(S/A) → 3개월 +15%, 6개월 +45% (독자 상승)
  # 비랠리 시 + 비주도주(D) → 3개월 -5%, 6개월 +10% (거의 정체)

  # → 결론: 주도주는 섹터 무관 성장력, 비주도주는 섹터 의존적
  ```

**Step 6: 이상치(Outlier) 케이스 분석**
- **목적**: 극단적 성공/실패 케이스의 특별한 점 발견
- **분석 방법**:
  - IQR, Z-score로 이상치 탐지
  - 초대박 케이스 (Level 4 중 2000%+) 심층 분석
  - 대폭락 케이스 (Level 0 중 -50%+) 심층 분석
  - 예상 밖 케이스 (Expected vs Actual 큰 차이) 분석
- **주요 분석 질문**:
  - **초대박 케이스 (2000%+)**:
    - 공통 팩터: 역사적 신고가 + 미래 산업 + 강한 수급?
    - 특별한 외부 요인 (산업 호황, 정책 지원 등)
  - **대폭락 케이스 (-50%+)**:
    - 악재 발생? (실적 쇼크, 회계 이슈 등)
    - 신고가 등급 F + 개인 주도 수급?
  - **예상 밖의 성공**: 신고가 F등급인데 Level 3 달성
    - 어떤 다른 팩터가 보완했는가?
  - **예상 밖의 실패**: 신고가 S등급인데 Level 0
    - 어떤 팩터가 부족했는가? (수급? 재무?)

**Step 7: 패턴 검증 (Validation)**
- **목적**: 발견한 패턴이 우연이 아닌지, 과적합이 아닌지 검증
- **분석 방법**:
  - Bootstrap 리샘플링 (1000회)으로 패턴 재현성 확인
  - 시간대별 분할 검증
    - Train: 2015-2019 케이스
    - Test: 2020-2024 케이스
    - 같은 패턴이 두 기간에서 모두 유효한가?
  - Permutation Test로 통계적 유의성 검증
  - Cross-validation으로 일반화 성능 확인
- **주요 검증 질문**:
  - 발견한 "필수 조건"이 전체 기간에서 유효한가?
  - 2015-2019와 2020-2024에서 팩터 중요도가 다른가?
  - 과적합 방지: 너무 세부적인 조건은 아닌가?

**종합 분석 결과**:
```
성공/실패 결정 팩터 (Level 0 vs 1~4)
├─ 필수 조건: 신고가 등급 C 이상
├─ 중요 조건: 외국인+기관 순매수
└─ 선호 조건: 재무 턴어라운드

성공 케이스 내 Level 결정 팩터 (Level 1→4)
├─ Level 1→2: 신고가 등급 B 이상
├─ Level 2→3: 신고가 등급 A + 미래 산업
└─ Level 3→4: 신고가 S등급 + 강한 수급 + 턴어라운드
```

#### 3.3.2 지도 학습 - 성공 패턴 예측

**목적**: 알려진 성공 패턴 템플릿 기반으로 신규 케이스의 성공 확률 예측

**라벨링 전략**:
```python
# 기본 성공 정의
is_success = (max_return_5y >= 50)  # 50% 이상

# 수익률 구간 분류
level = None
if max_return_5y >= 1000:
    level = 4  # 초고수익
elif max_return_5y >= 300:
    level = 3  # 고수익
elif max_return_5y >= 100:
    level = 2  # 중수익
elif max_return_5y >= 50:
    level = 1  # 저수익
else:
    level = 0  # 실패

# ========== 수익 실현 기간 분석 ==========
# 50% 도달까지 걸린 시간
days_to_50pct = None  # 50% 도달 일수 (미달성 시 None)
days_to_100pct = None  # 100% 도달 일수
days_to_peak = 450  # 최고 수익률 도달 일수

# 기간 구간 분류
time_to_target = None
if days_to_50pct is None:
    time_to_target = "미달성"
elif days_to_50pct <= 90:
    time_to_target = "초단기(3개월 이내)"
elif days_to_50pct <= 180:
    time_to_target = "단기(6개월 이내)"
elif days_to_50pct <= 365:
    time_to_target = "중기(1년 이내)"
elif days_to_50pct <= 730:
    time_to_target = "장기(2년 이내)"
else:
    time_to_target = "초장기(2년 이상)"

# ========== 최대 낙폭(MDD) 분석 ==========
# 2번 블록 고점 대비 최대 하락률
mdd_from_block_high = -25.5  # % (음수)
mdd_date = "2019-12-15"  # MDD 발생일
days_to_mdd = 117  # 2번 블록 고점 → MDD까지 일수

# MDD 구간 분류
mdd_severity = None
if mdd_from_block_high >= -10:
    mdd_severity = "경미(-10% 이내)"
elif mdd_from_block_high >= -20:
    mdd_severity = "보통(-20% 이내)"
elif mdd_from_block_high >= -30:
    mdd_severity = "심각(-30% 이내)"
else:
    mdd_severity = "매우심각(-30% 초과)"

# ========== 실패 케이스 상세 분석 ==========
# 5년 후에도 50% 미달성 케이스
if level == 0:
    failure_analysis = {
        "final_return_5y": -15.5,  # 5년 후 최종 수익률
        "is_continuous_decline": True,  # 지속 하락 여부
        "max_return_during_5y": 25.0,  # 5년 중 최고 수익률
        "days_to_max": 180,  # 최고점 도달 일수
        "decline_after_peak": -40.5,  # 최고점 이후 하락폭
        "below_block_high_days": 1200,  # 블록 고점 아래 머문 일수
        "trend": "실패-지속하락",  # 실패 패턴 유형
    }
else:
    failure_analysis = None

# ========== 리스크-수익 프로파일 ==========
risk_reward_profile = {
    "level": level,
    "max_return_5y": max_return_5y,
    "days_to_50pct": days_to_50pct,
    "time_to_target": time_to_target,
    "mdd_from_block_high": mdd_from_block_high,
    "mdd_severity": mdd_severity,
    "risk_reward_ratio": max_return_5y / abs(mdd_from_block_high) if mdd_from_block_high != 0 else None,
}
```

**모델 유형**:
- **분류 모델 (성공/실패)**
  - Random Forest, XGBoost, LightGBM
  - 신경망 (MLP)

- **회귀 모델 (수익률 예측)**
  - Gradient Boosting
  - 딥러닝: LSTM (시계열 특성 반영)

- **Multi-class 분류 (Level 0~4)**
  - XGBoost, LightGBM
  - 각 Level 달성 확률 예측

**특성 벡터 구성**:
```python
features = {
    # 거래량 블록
    'primary_trading_value_score': 7.5,
    'secondary_pattern': 'D+D+1',
    'secondary_trading_value_max': 2500,

    # 신고가 분석
    'new_high_grade': 'A',  # S/A/B/C/D/E/F
    'new_high_score': 8,

    # 당일 수급 (스냅샷)
    'is_d_foreign_institutional_buying': True,
    'd_foreign_institutional_net_buy': 27000000000,

    # 수급 트렌드
    'foreign_consecutive_buy_days': 35,
    'supply_demand_balance_score': 8.5,
    'dominance': 'foreign+institutional',

    # 재무제표 트렌드
    'has_turnaround': True,
    'consecutive_profit_quarters': 3,
    'equity_growth_rate': 42.9,

    # 산업 트렌드
    'is_future_industry': True,
    'future_industry_score': 9.0,
    'search_trend_score': 9.2,

    # ========== 섹터/테마 주도주 분석 (핵심 추가) ==========
    # 주도성 종합
    'leadership_score': 9.2,                       # 주도주 점수 (0-10)
    'leadership_grade': 'A',                       # S/A/B/C/D

    # 상대 강도 (Relative Strength)
    'relative_strength_percentile': 95.6,          # 섹터 내 상대 강도 백분위
    'outperformance_3m': 57.3,                     # 섹터 평균 대비 3개월 초과 수익률 (%)
    'outperformance_6m': 143.2,                    # 섹터 평균 대비 6개월 초과 수익률 (%)
    'is_early_mover': True,                        # 섹터 랠리 선행 여부
    'lead_days': 10,                               # 섹터 대비 선행 일수

    # 시장 지수 대비
    'vs_kospi_3m': 88.5,                           # KOSPI 대비 3개월 초과 수익률 (%)
    'vs_kospi_6m': 215.8,                          # KOSPI 대비 6개월 초과 수익률 (%)
    'vs_kosdaq_3m': 75.3,                          # KOSDAQ 대비 3개월 초과 수익률 (%)
    'vs_kosdaq_6m': 195.2,                         # KOSDAQ 대비 6개월 초과 수익률 (%)
    'sector_vs_kospi_6m': 85.5,                    # 섹터의 KOSPI 대비 6개월 초과 수익률 (%)
    'sector_vs_kosdaq_6m': 72.3,                   # 섹터의 KOSDAQ 대비 6개월 초과 수익률 (%)

    # 거래량 우위
    'trading_value_rank': 1,                       # 섹터 내 거래대금 순위
    'trading_value_ratio': 2.94,                   # 섹터 평균 대비 거래대금 배율
    'is_volume_leader': True,                      # 거래량 선행 주도 여부

    # 시가총액 및 수급
    'market_cap_rank': 1,                          # 섹터 내 시총 순위
    'market_cap_share': 22.5,                      # 섹터 시총 대비 점유율 (%)

    # 1번 블록 D일 수급
    'block_1_d_institutional_buy': 5000000000,     # 1번 블록 D일 기관 매수 금액 (원)
    'block_1_d_foreign_buy': 8000000000,           # 1번 블록 D일 외국인 매수 금액 (원)

    # 2번 블록 D일 수급
    'block_2_d_institutional_buy': 12000000000,    # 2번 블록 D일 기관 매수 금액 (원)
    'block_2_d_foreign_buy': 15000000000,          # 2번 블록 D일 외국인 매수 금액 (원)

    # 2번 블록 D+1일 수급
    'block_2_d1_institutional_buy': 8000000000,    # 2번 블록 D+1일 기관 매수 금액 (원)
    'block_2_d1_foreign_buy': 10000000000,         # 2번 블록 D+1일 외국인 매수 금액 (원)

    # 2번 블록 D+2일 수급
    'block_2_d2_institutional_buy': 6000000000,    # 2번 블록 D+2일 기관 매수 금액 (원)
    'block_2_d2_foreign_buy': 7000000000,          # 2번 블록 D+2일 외국인 매수 금액 (원)

    # 언론/이슈 주도성
    'is_sector_representative': True,              # 섹터 대표 종목 여부
    'sector_news_mention_ratio': 45.5,             # 섹터 뉴스 중 언급 비율 (%)
    'analyst_coverage': 18,                        # 애널리스트 커버리지 수
}
```

**예측 목표**:
❌ ~~매수/매도 신호 생성~~ (단기 트레이딩 아님)
✅ **장기 투자 성공 확률 및 리스크 예측**
  - **수익률 예측**
    - 50% 이상 달성 확률
    - Level 2 이상 달성 확률
    - 예상 최대 수익률 범위
  - **기간 예측**
    - 50% 도달까지 예상 소요 기간
    - 초단기/단기/중기/장기 분류 확률
  - **리스크 예측**
    - 예상 최대 낙폭(MDD)
    - MDD 심각도 (경미/보통/심각)
    - 리스크-수익 비율
  - **실패 확률 및 패턴**
    - 5년 후 50% 미달성 확률
    - 실패 시 예상 하락폭
    - 지속 하락 패턴 가능성

---

#### 지도 학습 상세 단계

##### Step 1: 특성 공학 (Feature Engineering)

**1.1 기본 특성 정규화 및 변환**
```python
# 수치형 특성 스케일링
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

# 정규 분포에 가까운 특성: StandardScaler
features_normal = ['equity_growth_rate', 'revenue_growth_rate']
scaler_std = StandardScaler()

# 범위가 정해진 특성: MinMaxScaler
features_bounded = ['supply_demand_balance_score', 'future_industry_score']
scaler_minmax = MinMaxScaler()

# 이상치에 강건한 스케일링: RobustScaler (중앙값, IQR 사용)
features_with_outliers = ['d_foreign_institutional_net_buy', 'trading_value']
scaler_robust = RobustScaler()

# 범주형 특성 인코딩
# One-Hot Encoding: 순서 없는 범주 (산업 분류, 시장 구분)
from sklearn.preprocessing import OneHotEncoder
categorical_features = ['industry_category', 'market_type']

# Ordinal Encoding: 순서 있는 범주 (신고가 등급 S>A>B>C>D>E>F)
from sklearn.preprocessing import OrdinalEncoder
ordinal_features = ['new_high_grade', 'mdd_severity']
grade_order = [['F', 'E', 'D', 'C', 'B', 'A', 'S']]
```

**1.2 파생 특성 생성 (Derived Features)**
```python
# 비율 및 복합 지표
features['institutional_foreign_ratio'] = (
    features['d_institutional_net_buy'] /
    (features['d_foreign_net_buy'] + 1e-9)
)

# 거래량 블록 강도 비율
features['block_intensity_ratio'] = (
    features['secondary_trading_value_max'] /
    features['primary_trading_value_score']
)

# 재무 건전성 복합 지표
features['financial_health_score'] = (
    features['consecutive_profit_quarters'] * 0.4 +
    features['equity_growth_rate'] * 0.3 +
    features['revenue_growth_rate'] * 0.3
)

# 모멘텀 지표
features['total_momentum_score'] = (
    features['supply_demand_balance_score'] * 0.5 +
    features['future_industry_score'] * 0.3 +
    features['search_trend_score'] * 0.2
)

# ========== 섹터/테마 주도주 파생 특성 (핵심 추가) ==========
# 주도성 복합 점수
features['leadership_composite_score'] = (
    features['relative_strength_percentile'] * 0.35 +  # 상대 강도 35%
    features['trading_value_ratio'] * 10 * 0.25 +      # 거래량 우위 25%
    features['market_cap_share'] * 0.20 +              # 시총 점유율 20%
    features['sector_news_mention_ratio'] * 0.20       # 언론 주도성 20%
)

# 주도주 + 신고가 등급 조합 (골든 크로스)
features['leader_high_grade_combo'] = (
    (features['leadership_grade'].isin(['S', 'A'])) &
    (features['new_high_grade'].isin(['S', 'A']))
).astype(int)

# 주도성 부족 + 고평가 (위험 신호)
features['non_leader_overvalued'] = (
    (features['leadership_grade'] == 'D') &
    (features['new_high_grade'].isin(['E', 'F']))
).astype(int)

# 섹터 초과 수익률 가속도 (모멘텀)
features['outperformance_acceleration'] = (
    features['outperformance_6m'] - features['outperformance_3m'] * 2
)

# 주도성 지속력 (선행성 + 대표성)
features['leadership_sustainability'] = (
    features['lead_days'] * 0.5 +                      # 선행 일수
    features['is_sector_representative'] * 30 +        # 섹터 대표성 (boolean → 가중치)
    features['analyst_coverage'] * 2                   # 애널리스트 커버리지
)

# 시간 기반 특성 (계절성, 요일 효과)
features['block_month'] = pd.to_datetime(features['block_2_date']).dt.month
features['block_quarter'] = pd.to_datetime(features['block_2_date']).dt.quarter
features['is_year_end'] = features['block_month'].isin([11, 12])
```

**1.3 비지도 학습 결과 활용**
```python
# Step 1.5: 비지도 학습에서 발견한 클러스터 정보를 특성으로 추가
features['unsupervised_cluster'] = cluster_labels  # K-means, DBSCAN 결과
features['cluster_success_rate'] = cluster_success_rates[cluster_labels]

# Step 2: PCA, t-SNE 차원 축소 결과
features['pca_component_1'] = pca_result[:, 0]
features['pca_component_2'] = pca_result[:, 1]

# Step 3: SHAP 기반 중요 특성 강조
# 비지도 학습에서 발견한 고위험/고수익 패턴 플래그
features['is_high_risk_high_return_pattern'] = (
    (features['mdd_from_block_high'] < -30) &
    (features['max_return_5y'] > 500)
)
```

**1.4 상호작용 특성 (Interaction Features)**
```python
# 2-way 상호작용: 중요 특성 간 곱셈
features['financial_x_industry'] = (
    features['financial_health_score'] *
    features['future_industry_score']
)

features['supply_x_momentum'] = (
    features['foreign_consecutive_buy_days'] *
    features['secondary_trading_value_max']
)

# ========== 주도주 상호작용 특성 (핵심 추가) ==========
# 주도성 x 재무 건전성
features['leadership_x_financial'] = (
    features['leadership_score'] *
    features['financial_health_score']
)
# 해석: 주도주이면서 재무도 좋으면 안정적 고수익 가능성 ↑

# 주도성 x 미래 산업
features['leadership_x_future_industry'] = (
    features['leadership_score'] *
    features['future_industry_score']
)
# 해석: 주도주 + 미래 산업 = 초고수익(Level 4) 가능성 ↑

# 주도성 x 신고가 점수
features['leadership_x_new_high'] = (
    features['leadership_score'] *
    features['new_high_score']
)
# 해석: 주도주 + 역사적 신고가 = 폭발적 상승 가능성 ↑

# 주도성 x 수급 강도
features['leadership_x_supply_demand'] = (
    features['leadership_score'] *
    features['supply_demand_balance_score']
)
# 해석: 주도주 + 강한 수급 = 지속 상승 가능성 ↑

# 상대 강도 x 거래량 우위
features['relative_strength_x_volume'] = (
    features['relative_strength_percentile'] / 100 *
    features['trading_value_ratio']
)
# 해석: 수익률도 1위, 거래량도 1위 = 확실한 주도주

# 3-way 상호작용: 초고수익 예측에 중요한 조합
features['triple_golden_combo'] = (
    features['has_turnaround'] *
    features['is_future_industry'] *
    features['is_d_foreign_institutional_buying']
)

# 3-way 주도주 황금 조합
features['leadership_golden_combo'] = (
    features['is_sector_leader'] *
    features['is_future_industry'] *
    features['has_turnaround']
)
# 해석: 주도주 + 미래 산업 + 턴어라운드 = Level 4 확률 90%+

# Polynomial Features (2차, 3차)
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2, interaction_only=False)
# 주의: 특성 개수가 급증하므로 주요 특성만 선택
```

**1.5 시계열 특성 (Time-Series Features)**
```python
# 비지도 학습 Step 4 (DTW 분석) 결과 활용
features['price_pattern_cluster'] = dtw_cluster_labels
features['pattern_avg_return'] = pattern_cluster_avg_returns[dtw_cluster_labels]

# 초기 수익률 구간별 특성
features['return_1m'] = return_after_1month
features['return_3m'] = return_after_3months
features['return_6m'] = return_after_6months

# 변동성 지표
features['volatility_1m'] = rolling_std_1month
features['max_drawdown_1m'] = max_drawdown_1month
```

##### Step 2: 모델 선택 및 학습

**2.1 분류 모델 1: 성공/실패 예측 (Binary Classification)**

**목표**: `is_success` (50% 이상 달성 여부) 예측

**모델 후보**:
```python
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

models_binary = {
    'logistic': LogisticRegression(class_weight='balanced', max_iter=1000),
    'random_forest': RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        class_weight='balanced',
        random_state=42
    ),
    'xgboost': XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        scale_pos_weight=len(y[y==0]) / len(y[y==1]),  # 클래스 불균형 처리
        random_state=42
    ),
    'lightgbm': LGBMClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        class_weight='balanced',
        random_state=42
    ),
    'catboost': CatBoostClassifier(
        iterations=200,
        depth=6,
        learning_rate=0.05,
        auto_class_weights='Balanced',
        verbose=False,
        random_state=42
    ),
    'mlp': MLPClassifier(
        hidden_layers=(64, 32, 16),
        activation='relu',
        solver='adam',
        max_iter=500,
        random_state=42
    ),
}
```

**성능 지표**:
```python
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, classification_report,
    confusion_matrix, precision_recall_curve
)

# 클래스 불균형 고려: Precision, Recall, F1-Score 중시
# - Precision: 성공 예측 시 실제 성공 비율 (False Positive 최소화)
# - Recall: 실제 성공 케이스 중 예측 성공 비율 (False Negative 최소화)
# - F1-Score: Precision과 Recall의 조화평균

# 투자 전략상 중요:
# - High Precision: 예측 성공 케이스에 투자 → 실패 최소화
# - High Recall: 가능한 많은 성공 케이스 포착 → 기회 최대화
# 목표: F1-Score 최대화 (둘 다 균형)
```

**2.2 분류 모델 2: Level 다중 분류 (Multi-class Classification)**

**목표**: `return_level` (0~4) 예측

```python
models_multiclass = {
    'random_forest': RandomForestClassifier(
        n_estimators=300,
        max_depth=12,
        class_weight='balanced',
        random_state=42
    ),
    'xgboost': XGBClassifier(
        n_estimators=300,
        max_depth=8,
        learning_rate=0.03,
        objective='multi:softprob',  # 다중 클래스 확률 예측
        num_class=5,  # Level 0~4
        random_state=42
    ),
    'lightgbm': LGBMClassifier(
        n_estimators=300,
        max_depth=8,
        learning_rate=0.03,
        objective='multiclass',
        num_class=5,
        class_weight='balanced',
        random_state=42
    ),
}

# 성능 지표: Macro/Weighted F1-Score
# - Macro: 각 클래스 동등하게 취급
# - Weighted: 클래스 빈도 고려 (Level 1이 많으면 가중치 높음)
from sklearn.metrics import f1_score

f1_macro = f1_score(y_true, y_pred, average='macro')
f1_weighted = f1_score(y_true, y_pred, average='weighted')

# Confusion Matrix: 어느 Level 간 혼동이 많은지 분석
cm = confusion_matrix(y_true, y_pred)
# 예: Level 3 → Level 2 혼동이 많음 → 중수익/고수익 경계 모호
```

**2.3 회귀 모델: 수익률 예측 (Regression)**

**목표**: `max_return_5y` (연속형 수익률) 예측

```python
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.svm import SVR

models_regression = {
    'ridge': Ridge(alpha=1.0),
    'lasso': Lasso(alpha=1.0),
    'elastic_net': ElasticNet(alpha=1.0, l1_ratio=0.5),
    'random_forest': RandomForestRegressor(
        n_estimators=300,
        max_depth=12,
        random_state=42
    ),
    'xgboost': XGBRegressor(
        n_estimators=300,
        max_depth=8,
        learning_rate=0.03,
        objective='reg:squarederror',
        random_state=42
    ),
    'lightgbm': LGBMRegressor(
        n_estimators=300,
        max_depth=8,
        learning_rate=0.03,
        objective='regression',
        random_state=42
    ),
}

# 성능 지표
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae = mean_absolute_error(y_true, y_pred)  # 평균 절대 오차
mse = mean_squared_error(y_true, y_pred)   # 평균 제곱 오차
rmse = np.sqrt(mse)                         # 제곱근 평균 제곱 오차
r2 = r2_score(y_true, y_pred)               # 결정계수 (설명력)

# MAPE (Mean Absolute Percentage Error): 상대 오차
mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-9))) * 100
```

**2.4 기간 예측 모델: 수익 실현 시간 (Time-to-Event)**

**목표**: `days_to_50pct`, `time_to_target` 예측

```python
# Regression: days_to_50pct (연속형)
# 미달성 케이스(None) 처리:
# - 옵션 1: 최대값(1825일 = 5년)으로 대체
# - 옵션 2: 미달성 케이스 제외하고 학습

# Classification: time_to_target (범주형)
# 클래스: 초단기/단기/중기/장기/초장기/미달성

models_time = {
    'xgboost_reg': XGBRegressor(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        random_state=42
    ),
    'lightgbm_clf': LGBMClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        num_class=6,  # 6개 구간
        class_weight='balanced',
        random_state=42
    ),
}
```

**2.5 리스크 예측 모델: MDD 예측**

**목표**: `mdd_from_block_high` (연속형), `mdd_severity` (범주형)

```python
# Regression: MDD % 값 예측
models_mdd_reg = {
    'xgboost': XGBRegressor(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        objective='reg:squarederror',
        random_state=42
    ),
}

# Classification: MDD 심각도 예측 (경미/보통/심각/매우심각)
models_mdd_clf = {
    'lightgbm': LGBMClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.05,
        num_class=4,
        class_weight='balanced',
        random_state=42
    ),
}
```

##### Step 3: 교차 검증 및 하이퍼파라미터 튜닝

**3.1 시계열 고려 교차 검증 (Time-Series Split)**

```python
from sklearn.model_selection import TimeSeriesSplit

# 일반 K-Fold는 시계열 데이터에 부적합 (미래 데이터로 과거 학습)
# TimeSeriesSplit: 과거 데이터로 학습 → 미래 데이터로 검증

tscv = TimeSeriesSplit(n_splits=5)

for train_idx, val_idx in tscv.split(X):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    score = f1_score(y_val, y_pred)
    print(f"Fold Score: {score:.4f}")

# 예: 2015-2024 데이터
# Fold 1: Train 2015-2017, Val 2018
# Fold 2: Train 2015-2018, Val 2019
# Fold 3: Train 2015-2019, Val 2020
# Fold 4: Train 2015-2020, Val 2021-2022
# Fold 5: Train 2015-2022, Val 2023-2024
```

**3.2 하이퍼파라미터 튜닝**

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from skopt import BayesSearchCV

# GridSearchCV: 모든 조합 탐색 (시간 오래 걸림)
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [6, 8, 10, 12],
    'learning_rate': [0.01, 0.03, 0.05, 0.1],
    'subsample': [0.8, 0.9, 1.0],
}

grid_search = GridSearchCV(
    XGBClassifier(random_state=42),
    param_grid,
    cv=tscv,
    scoring='f1',
    n_jobs=-1,
    verbose=2
)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

# RandomizedSearchCV: 랜덤 샘플링 (빠름)
param_distributions = {
    'n_estimators': [100, 150, 200, 250, 300],
    'max_depth': [4, 6, 8, 10, 12, 14],
    'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
}

random_search = RandomizedSearchCV(
    XGBClassifier(random_state=42),
    param_distributions,
    n_iter=50,  # 50개 조합 랜덤 샘플링
    cv=tscv,
    scoring='f1',
    n_jobs=-1,
    random_state=42,
    verbose=2
)
random_search.fit(X_train, y_train)

# BayesSearchCV: 베이지안 최적화 (효율적)
from skopt.space import Real, Integer

search_spaces = {
    'n_estimators': Integer(100, 500),
    'max_depth': Integer(4, 15),
    'learning_rate': Real(0.01, 0.3, prior='log-uniform'),
    'subsample': Real(0.6, 1.0),
    'colsample_bytree': Real(0.6, 1.0),
}

bayes_search = BayesSearchCV(
    XGBClassifier(random_state=42),
    search_spaces,
    n_iter=30,
    cv=tscv,
    scoring='f1',
    n_jobs=-1,
    random_state=42,
    verbose=2
)
bayes_search.fit(X_train, y_train)
```

**3.3 클래스 불균형 처리**

```python
# 문제: Level 4 (초고수익) 케이스가 매우 적음
# 해결책:

# 1) SMOTE (Synthetic Minority Over-sampling Technique)
from imblearn.over_sampling import SMOTE, ADASYN
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# 2) Class Weight 조정
# XGBoost: scale_pos_weight
# LightGBM: class_weight='balanced'
# CatBoost: auto_class_weights='Balanced'

# 3) Stratified Sampling: 클래스 비율 유지
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

##### Step 4: 모델 해석 (Model Interpretation)

**4.1 특성 중요도 (Feature Importance)**

```python
# Tree 기반 모델: 기본 feature_importances_
importances = model.feature_importances_
feature_names = X.columns
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

# Permutation Importance: 모델 독립적
from sklearn.inspection import permutation_importance
perm_importance = permutation_importance(
    model, X_val, y_val,
    n_repeats=10,
    random_state=42
)
```

**4.2 SHAP (SHapley Additive exPlanations)**

```python
import shap

# Tree 기반 모델용 TreeExplainer (빠름)
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_val)

# SHAP Summary Plot: 전체 데이터셋의 특성 영향도
shap.summary_plot(shap_values, X_val, feature_names=feature_names)

# SHAP Force Plot: 개별 예측 설명
shap.force_plot(
    explainer.expected_value,
    shap_values[0],
    X_val.iloc[0]
)

# SHAP Dependence Plot: 특정 특성의 영향 시각화
shap.dependence_plot(
    'future_industry_score',
    shap_values,
    X_val
)

# 예시 해석:
# - future_industry_score가 9.0 이상일 때 Level 4 확률 급증
# - foreign_consecutive_buy_days > 30일 때 성공 확률 +25%p
# - has_turnaround=True일 때 Level 3 이상 확률 +18%p
```

**4.3 부분 의존성 플롯 (Partial Dependence Plot)**

```python
from sklearn.inspection import PartialDependenceDisplay

features_to_plot = [
    'future_industry_score',
    'foreign_consecutive_buy_days',
    'equity_growth_rate',
    'return_6m'
]

PartialDependenceDisplay.from_estimator(
    model,
    X_val,
    features_to_plot,
    kind='average'
)

# 2-way PDP: 두 특성 간 상호작용 시각화
PartialDependenceDisplay.from_estimator(
    model,
    X_val,
    [('future_industry_score', 'equity_growth_rate')],
    kind='average'
)
```

**4.4 개별 예측 설명 (Individual Prediction Explanation)**

```python
# LIME (Local Interpretable Model-agnostic Explanations)
import lime
import lime.lime_tabular

explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train.values,
    feature_names=feature_names,
    class_names=['Fail', 'Level1', 'Level2', 'Level3', 'Level4'],
    mode='classification'
)

# 특정 케이스 설명
i = 42  # 설명할 케이스 인덱스
exp = explainer.explain_instance(
    X_val.iloc[i].values,
    model.predict_proba,
    num_features=10
)
exp.show_in_notebook()

# 예시 출력:
# Level 4 확률 85%
# 주요 기여 특성:
# - future_industry_score=9.2 → +35%
# - has_turnaround=True → +22%
# - return_6m=65% → +18%
# - foreign_consecutive_buy_days=42 → +10%
```

##### Step 5: 앙상블 및 스태킹 (Ensemble & Stacking)

**5.1 Voting Classifier/Regressor**

```python
from sklearn.ensemble import VotingClassifier, VotingRegressor

# Hard Voting: 다수결
voting_clf_hard = VotingClassifier(
    estimators=[
        ('rf', RandomForestClassifier(n_estimators=200, random_state=42)),
        ('xgb', XGBClassifier(n_estimators=200, random_state=42)),
        ('lgbm', LGBMClassifier(n_estimators=200, random_state=42)),
    ],
    voting='hard'
)

# Soft Voting: 확률 평균 (권장)
voting_clf_soft = VotingClassifier(
    estimators=[
        ('rf', RandomForestClassifier(n_estimators=200, random_state=42)),
        ('xgb', XGBClassifier(n_estimators=200, random_state=42)),
        ('lgbm', LGBMClassifier(n_estimators=200, random_state=42)),
    ],
    voting='soft'  # 각 모델의 확률 평균
)
voting_clf_soft.fit(X_train, y_train)

# Voting Regressor: 회귀 앙상블
voting_reg = VotingRegressor(
    estimators=[
        ('rf', RandomForestRegressor(n_estimators=200, random_state=42)),
        ('xgb', XGBRegressor(n_estimators=200, random_state=42)),
        ('lgbm', LGBMRegressor(n_estimators=200, random_state=42)),
    ]
)
voting_reg.fit(X_train, y_train)
```

**5.2 Stacking (Meta-Model)**

```python
from sklearn.ensemble import StackingClassifier, StackingRegressor

# Level 0: Base Models
base_models = [
    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)),
    ('xgb', XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, random_state=42)),
    ('lgbm', LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, random_state=42)),
    ('catboost', CatBoostClassifier(iterations=200, depth=6, verbose=False, random_state=42)),
]

# Level 1: Meta-Model
meta_model = LogisticRegression(max_iter=1000)

stacking_clf = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=5,  # Base 모델 학습 시 CV 사용
    stack_method='predict_proba',  # 확률 사용
    n_jobs=-1
)
stacking_clf.fit(X_train, y_train)

# Stacking Regressor
base_regressors = [
    ('rf', RandomForestRegressor(n_estimators=200, random_state=42)),
    ('xgb', XGBRegressor(n_estimators=200, random_state=42)),
    ('lgbm', LGBMRegressor(n_estimators=200, random_state=42)),
]
meta_regressor = Ridge(alpha=1.0)

stacking_reg = StackingRegressor(
    estimators=base_regressors,
    final_estimator=meta_regressor,
    cv=5
)
stacking_reg.fit(X_train, y_train)
```

**5.3 Blending**

```python
# Stacking과 유사하지만 Hold-out 방식 사용
from sklearn.model_selection import train_test_split

# 1) 데이터 분할: Train / Holdout / Test
X_train_base, X_holdout, y_train_base, y_holdout = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
)

# 2) Base 모델 학습 (Train)
base_predictions = []
for name, model in base_models:
    model.fit(X_train_base, y_train_base)
    pred = model.predict_proba(X_holdout)
    base_predictions.append(pred)

# 3) Meta 데이터 생성 (Holdout)
X_meta = np.hstack(base_predictions)

# 4) Meta 모델 학습
meta_model.fit(X_meta, y_holdout)

# 5) 최종 예측 (Test)
test_predictions = []
for name, model in base_models:
    pred = model.predict_proba(X_test)
    test_predictions.append(pred)
X_test_meta = np.hstack(test_predictions)
final_pred = meta_model.predict(X_test_meta)
```

##### Step 6: 성능 평가 및 검증

**6.1 종합 성능 리포트**

```python
from sklearn.metrics import classification_report, confusion_matrix

# Binary Classification (성공/실패)
y_pred_binary = model_binary.predict(X_test)
y_proba_binary = model_binary.predict_proba(X_test)[:, 1]

print("===== Binary Classification Report =====")
print(classification_report(y_test_binary, y_pred_binary,
                            target_names=['Fail', 'Success']))

# Confusion Matrix
cm_binary = confusion_matrix(y_test_binary, y_pred_binary)
print(f"Confusion Matrix:\n{cm_binary}")

# ROC-AUC
roc_auc = roc_auc_score(y_test_binary, y_proba_binary)
print(f"ROC-AUC: {roc_auc:.4f}")

# Precision-Recall Curve
from sklearn.metrics import average_precision_score
ap_score = average_precision_score(y_test_binary, y_proba_binary)
print(f"Average Precision: {ap_score:.4f}")

# Multi-class Classification (Level 0~4)
y_pred_multi = model_multi.predict(X_test)
y_proba_multi = model_multi.predict_proba(X_test)

print("\n===== Multi-class Classification Report =====")
print(classification_report(y_test_multi, y_pred_multi,
                            target_names=['Level0', 'Level1', 'Level2', 'Level3', 'Level4']))

cm_multi = confusion_matrix(y_test_multi, y_pred_multi)
print(f"Confusion Matrix:\n{cm_multi}")

# Regression (수익률 예측)
y_pred_reg = model_reg.predict(X_test)
mae = mean_absolute_error(y_test_reg, y_pred_reg)
rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))
r2 = r2_score(y_test_reg, y_pred_reg)

print("\n===== Regression Report =====")
print(f"MAE: {mae:.2f}%")
print(f"RMSE: {rmse:.2f}%")
print(f"R²: {r2:.4f}")
```

**6.2 시간별 성능 검증 (Temporal Validation)**

```python
# 기간별 성능 분석: 모델이 최근 데이터에도 잘 작동하는가?
periods = [
    ('2015-2017', X_test_2015_2017, y_test_2015_2017),
    ('2018-2020', X_test_2018_2020, y_test_2018_2020),
    ('2021-2024', X_test_2021_2024, y_test_2021_2024),
]

for period_name, X_period, y_period in periods:
    y_pred = model.predict(X_period)
    f1 = f1_score(y_period, y_pred, average='weighted')
    print(f"{period_name} F1-Score: {f1:.4f}")

# 예상 결과:
# 2015-2017 F1-Score: 0.82
# 2018-2020 F1-Score: 0.78
# 2021-2024 F1-Score: 0.75
# → 최근으로 올수록 성능 하락 가능 (시장 환경 변화)
```

**6.3 임계값 최적화 (Threshold Tuning)**

```python
# Binary Classification: 기본 임계값 0.5 → 최적화
from sklearn.metrics import precision_recall_curve

y_proba = model.predict_proba(X_val)[:, 1]
precisions, recalls, thresholds = precision_recall_curve(y_val, y_proba)

# F1-Score 최대화 임계값 찾기
f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-9)
best_threshold_idx = np.argmax(f1_scores)
best_threshold = thresholds[best_threshold_idx]

print(f"Best Threshold: {best_threshold:.3f}")
print(f"Best F1-Score: {f1_scores[best_threshold_idx]:.4f}")

# 투자 전략별 임계값 조정:
# - 보수적 전략 (High Precision): threshold = 0.7
#   → 성공 확률 70% 이상만 투자 (False Positive ↓)
# - 공격적 전략 (High Recall): threshold = 0.3
#   → 성공 가능성 있는 모든 케이스 포착 (False Negative ↓)
```

**6.4 오류 분석 (Error Analysis)**

```python
# False Positive 분석: 실패했는데 성공 예측
fp_indices = np.where((y_test == 0) & (y_pred == 1))[0]
fp_cases = X_test.iloc[fp_indices]

print(f"===== False Positive Cases (n={len(fp_indices)}) =====")
print(fp_cases.describe())

# 공통 패턴 분석:
# - 초기 모멘텀 강했으나 지속력 부족?
# - 산업 트렌드 급변?
# - 재무 악화 미감지?

# False Negative 분석: 성공했는데 실패 예측
fn_indices = np.where((y_test == 1) & (y_pred == 0))[0]
fn_cases = X_test.iloc[fn_indices]

print(f"===== False Negative Cases (n={len(fn_indices)}) =====")
print(fn_cases.describe())

# 공통 패턴 분석:
# - 늦게 상승한 케이스? (초기 모멘텀 약함)
# - 비인기 산업에서 성공?
# - 재무 지표 약했으나 다른 요인으로 성공?
```

##### Step 7: 최종 모델 선택 및 저장

**7.1 모델 비교 및 선택**

```python
import pandas as pd

# 모든 모델 성능 비교
results = {
    'Model': [],
    'F1-Score': [],
    'Precision': [],
    'Recall': [],
    'ROC-AUC': [],
    'Training Time (s)': [],
}

for name, model in models_binary.items():
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    y_pred = model.predict(X_val)
    y_proba = model.predict_proba(X_val)[:, 1]

    results['Model'].append(name)
    results['F1-Score'].append(f1_score(y_val, y_pred))
    results['Precision'].append(precision_score(y_val, y_pred))
    results['Recall'].append(recall_score(y_val, y_pred))
    results['ROC-AUC'].append(roc_auc_score(y_val, y_proba))
    results['Training Time (s)'].append(training_time)

results_df = pd.DataFrame(results).sort_values('F1-Score', ascending=False)
print(results_df)

# 예시 결과:
#         Model  F1-Score  Precision  Recall  ROC-AUC  Training Time (s)
# 4    catboost     0.845      0.820   0.872    0.912               45.2
# 2     xgboost     0.838      0.815   0.863    0.908               12.5
# 3    lightgbm     0.835      0.810   0.862    0.905                8.3
# 1  random_forest  0.825      0.800   0.852    0.895               25.7
# 5         mlp     0.810      0.785   0.837    0.882               120.5
# 0    logistic     0.752      0.735   0.770    0.825                1.2

# 최종 선택: CatBoost (F1-Score 최고, ROC-AUC 최고)
best_model = CatBoostClassifier(iterations=300, depth=6, learning_rate=0.03,
                                 auto_class_weights='Balanced', verbose=False)
best_model.fit(X_train, y_train)
```

**7.2 모델 저장 및 버전 관리**

```python
import joblib
import pickle
from datetime import datetime

# 모델 저장
model_version = datetime.now().strftime("%Y%m%d_%H%M%S")
model_path = f"models/level_classifier_{model_version}.pkl"

joblib.dump(best_model, model_path)
print(f"Model saved: {model_path}")

# 메타데이터 저장
metadata = {
    'model_type': 'CatBoostClassifier',
    'version': model_version,
    'training_data_period': '2015-01-01 to 2024-12-31',
    'n_samples': len(X_train),
    'n_features': X_train.shape[1],
    'feature_names': list(X_train.columns),
    'performance': {
        'f1_score': 0.845,
        'precision': 0.820,
        'recall': 0.872,
        'roc_auc': 0.912,
    },
    'hyperparameters': best_model.get_params(),
}

import json
metadata_path = f"models/level_classifier_{model_version}_metadata.json"
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)

# 모델 로드
loaded_model = joblib.load(model_path)
y_pred = loaded_model.predict(X_new)
```

**7.3 프로덕션 배포 준비**

```python
# 1) 특성 변환 파이프라인 저장
from sklearn.pipeline import Pipeline

preprocessing_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('feature_engineering', FeatureEngineeringTransformer()),
    ('model', best_model)
])

preprocessing_pipeline.fit(X_train, y_train)
joblib.dump(preprocessing_pipeline, f"models/pipeline_{model_version}.pkl")

# 2) 입력 검증 함수
def validate_input(input_data):
    required_features = [
        'primary_trading_value_score',
        'secondary_pattern',
        'new_high_grade',
        'is_d_foreign_institutional_buying',
        'd_foreign_institutional_net_buy',
        'foreign_consecutive_buy_days',
        'has_turnaround',
        'is_future_industry',
        # ... 모든 필수 특성
    ]

    for feature in required_features:
        if feature not in input_data:
            raise ValueError(f"Missing required feature: {feature}")

    return True

# 3) 예측 함수
def predict_investment_success(stock_data):
    """
    입력: 1번+2번 블록 발생 주식 데이터
    출력: 성공 확률, Level 예측, 리스크 예측
    """
    validate_input(stock_data)

    # 전처리 + 예측
    X = pd.DataFrame([stock_data])

    # 성공/실패 예측
    success_proba = model_binary.predict_proba(X)[0, 1]

    # Level 예측
    level_pred = model_multi.predict(X)[0]
    level_proba = model_multi.predict_proba(X)[0]

    # 수익률 예측
    return_pred = model_reg.predict(X)[0]

    # MDD 예측
    mdd_pred = model_mdd_reg.predict(X)[0]

    # 기간 예측
    time_pred = model_time_clf.predict(X)[0]

    result = {
        'success_probability': float(success_proba),
        'predicted_level': int(level_pred),
        'level_probabilities': {
            'Level 0 (실패)': float(level_proba[0]),
            'Level 1 (50-100%)': float(level_proba[1]),
            'Level 2 (100-300%)': float(level_proba[2]),
            'Level 3 (300-1000%)': float(level_proba[3]),
            'Level 4 (1000%+)': float(level_proba[4]),
        },
        'expected_max_return': float(return_pred),
        'expected_mdd': float(mdd_pred),
        'expected_time_to_target': time_pred,
        'recommendation': _generate_recommendation(success_proba, level_pred, mdd_pred),
    }

    return result

def _generate_recommendation(success_proba, level_pred, mdd_pred):
    if success_proba >= 0.8 and level_pred >= 3 and mdd_pred > -20:
        return "강력 매수 추천 (High confidence, High return, Low risk)"
    elif success_proba >= 0.7 and level_pred >= 2:
        return "매수 추천 (Good probability, Moderate return)"
    elif success_proba >= 0.6:
        return "조건부 매수 (Moderate probability, Monitor closely)"
    else:
        return "보류 (Low success probability)"
```

### 3.4 백테스팅

- 과거 데이터 기반 모델 성능 검증
- 거래 비용 고려
- 리스크 관리 전략 적용
- 성과 지표 측정 (수익률, 샤프 비율, MDD 등)

### 3.5 성과 분석 및 라벨링 전략

#### 3.5.1 성공 판단 기준

- **기준점**: 2번 거래량 블록의 고점 (D, D+1, D+2 중 최고가)
- **기본 성공 정의**: 5년 내 기준점 대비 **50% 이상 상승** 달성
- **실패 정의**: 5년 내 50% 상승 미달성

#### 3.5.2 수익률 구간 분류

**목적:** 50% 이상 상승한 케이스 중에서, 어떤 조건일 때 더 높이 상승하는지 분석

- **Level 1 (저수익)**: 50% ~ 100% 미만
- **Level 2 (중수익)**: 100% ~ 300% 미만
- **Level 3 (고수익)**: 300% ~ 1000% 미만
- **Level 4 (초고수익)**: 1000% 이상

**분석 목표:**
- 각 수익률 구간의 공통 특징 발견
- Level 1 → Level 4로 갈수록 어떤 팩터가 강화되는가?
- 특정 팩터 조합이 초고수익을 만드는가?

#### 3.5.3 주가 흐름 패턴 데이터 수집

**2번 블록 이후 5년간 추적 데이터:**
- **일별 데이터** (첫 1년):
  - 일별 OHLCV
  - 2번 블록 고점 대비 수익률
  - 이동평균선 (5일, 20일, 60일, 120일)
  - 거래량 변화

- **주별 데이터** (5년 전체):
  - 주봉 OHLCV
  - 주봉 120MA 기울기
  - 주별 최고/최저 수익률
  - 누적 수익률

- **주요 이벤트 데이터**:
  - 최고점 도달 시점 및 수익률
  - 최저점(MDD) 발생 시점 및 낙폭
  - 100% 달성 시점 (성공 케이스만)
  - 주요 조정 구간 (20% 이상 하락)

#### 3.5.4 라벨 설계

**성공 여부 라벨:**
- `is_50pct_success`: 50% 이상 상승 달성 여부 (Boolean)
- `return_level`: 수익률 구간 (0=실패, 1=Level1, 2=Level2, 3=Level3, 4=Level4)
  - 0: 50% 미만
  - 1: 50~100%
  - 2: 100~300%
  - 3: 300~1000%
  - 4: 1000% 이상

**수익률 지표:**
- `peak_return_pct`: 5년 내 최고 수익률 (%)
- `days_to_50pct`: 50% 달성까지 소요 일수
- `days_to_100pct`: 100% 달성까지 소요 일수 (달성 시)
- `days_to_peak`: 최고점 도달까지 소요 일수

**위험 지표:**
- `max_drawdown_pct`: 최대 낙폭 (%)
- `max_drawdown_days`: 최대 낙폭 발생 시점
- `volatility`: 수익률 표준편차

**패턴 지표:**
- `num_corrections`: 20% 이상 조정 횟수
- `avg_correction_pct`: 평균 조정 폭
- `recovery_speed`: 조정 후 회복 속도 (일수)

### 3.6 비지도 학습 (Unsupervised Learning)

**핵심 목표:** 팩터 기반 분석을 통해 수익률 구간별 차별 요인 발견

**접근 방식:**

- 1번+2번 블록 발생 케이스에서 재무/산업/수급/기술적 팩터 분석
- 클러스터링을 통해 Level 1~4를 구분하는 핵심 팩터 발견
- 어떤 조건일 때 50% → 100% → 1000%까지 상승하는지 규칙 도출

---

#### 3.6.1 수익률 구간별 패턴 발견

**목적:** 50% 이상 달성한 케이스들을 수익률 구간별로 분석하여 차이점 발견

**Step 1: 데이터 준비**
- 1번+2번 블록 발생 케이스 전체 수집 (10년 → 예상 100~500개)
- 50% 이상 달성 케이스만 필터링
- 각 케이스를 `return_level`로 분류 (Level 1~4)
- 각 케이스별 특성 벡터 구성:
  - **블록 특성**: 1번/2번 블록 거래량, 거래대금, 패턴 유형
  - **재무 특성**: 영업이익 증가율, 자본총계 증가율, ROE, 매출 증가율
  - **산업 특성**: 산업 분류, 미래산업 여부
  - **수급 특성**: 외국인/기관 매수세, 순매수 지속일
  - **시장 특성**: 발생 시점의 코스피 지수, 변동성, 강세장/약세장
  - **초기 모멘텀**: 2번 블록 이후 1개월/3개월/6개월 수익률

**Step 2: 수익률 구간별 클러스터링**
- **알고리즘**: K-means, DBSCAN, Hierarchical Clustering
- **목표**: 각 수익률 구간(Level 1~4) 내에서도 세부 패턴 발견
- **클러스터 분석**:
  - Level 1 (50~100%): 어떤 특징?
  - Level 2 (100~300%): 어떤 특징?
  - Level 3 (300~1000%): 어떤 특징?
  - Level 4 (1000%+): 어떤 특징?

**Step 3: 수익률 구간별 차별 요인 분석**
- 각 Level의 평균 특성 비교
- **발견 예시:**
  ```
  Level 4 (1000%+ 초고수익):
  - 영업이익 5년 연속 증가: 95%
  - 자본총계 5년 연속 증가: 90%
  - 미래산업 (AI, 2차전지 등): 85%
  - 2번 블록 이후 6개월 수익률 > 50%: 80%
  - 외국인/기관 순매수 6개월 지속: 75%

  Level 3 (300~1000% 고수익):
  - 영업이익 3년 연속 증가: 80%
  - 자본총계 3년 연속 증가: 75%
  - 미래산업 포함: 60%
  - 2번 블록 이후 6개월 수익률 > 30%: 70%

  Level 2 (100~300% 중수익):
  - 영업이익 증가 (연속성 약함): 60%
  - 자본총계 증가: 55%
  - 전통 산업: 50%

  Level 1 (50~100% 저수익):
  - 영업이익 변동성 큼: 40%
  - 재무 개선 미약
  - 초기 모멘텀 약함
  ```

**Step 4: 레벨 간 팩터 강도 비교**
- 각 팩터가 Level 1 → Level 4로 갈수록 어떻게 변하는지 시각화
- 예: 영업이익 증가 연속성 (1년 → 3년 → 5년)
- 예: 초기 모멘텀 (10% → 30% → 50%)

**Step 5: 주가 흐름 패턴 시각화**
- 각 Level별 평균 주가 흐름 차트
- t-SNE, PCA로 2D 시각화
- 시간대별 수익률 분포

#### 3.6.2 차트 패턴 시계열 클러스터링

**목적:** 주가 차트 시계열 패턴으로 수익률 구간 그룹화 및 분석

**Step 1: 차트 데이터 준비**
- 2번 블록 이후 N일간의 시계열 데이터 수집
  - **가격 시퀀스**: 일별 종가 정규화 (2번 블록 고점 = 100 기준)
  - **수익률 시퀀스**: [0%, 2%, -1%, 5%, 3%, ...] (첫 60~360일)
  - **거래량 시퀀스**: 일별 거래량 정규화
  - **이동평균선**: 5일, 20일, 60일, 120일 MA

**Step 2: 시계열 클러스터링 (DTW)**
- **알고리즘**: Dynamic Time Warping (DTW) 거리 기반 클러스터링
- **목적**: 유사한 주가 흐름 패턴끼리 그룹화
- **분석 구간**:
  - 초기 3개월 패턴
  - 초기 6개월 패턴
  - 1년 패턴

**Step 3: 패턴별 수익률 분석**
- 각 클러스터의 평균 최종 수익률 계산
- **발견 예시:**
  ```
  패턴 A (급등 후 안정):
  - 초기 3개월 50% 급등 → 6개월간 횡보 → 재상승
  - 평균 5년 수익률: 800%
  - Level 3~4에 주로 분포

  패턴 B (완만 상승):
  - 초기 6개월 30% 상승 → 꾸준한 우상향
  - 평균 5년 수익률: 200%
  - Level 2에 주로 분포

  패턴 C (초기 조정):
  - 초기 3개월 -10% 조정 → 느린 회복
  - 평균 5년 수익률: 80%
  - Level 1에 주로 분포
  ```

**Step 4: 차트 패턴 특징 추출**
- **모멘텀 지표**:
  - 초기 1개월/3개월/6개월 수익률
  - 최대 상승폭, 최대 하락폭

- **변동성 지표**:
  - 표준편차
  - ATR (Average True Range)
  - 조정 빈도 및 깊이

- **추세 지표**:
  - 이동평균선 배열 (정배열/역배열 지속일)
  - 이동평균선 기울기
  - 추세선 각도

- **거래량 패턴**:
  - 거래량 증가/감소 추세
  - 급등일 거래량 패턴
  - 거래량 이동평균 대비 비율

**Step 5: 패턴 시각화**
- 각 클러스터별 대표 차트 추출
- Level 1~4별 평균 주가 흐름 차트
- t-SNE로 패턴 2D 시각화

**Step 6: 실시간 패턴 매칭**
- 새로운 케이스 발생 시
- 초기 60~180일 차트 패턴 수집
- DTW 거리로 가장 유사한 과거 클러스터 찾기
- 해당 클러스터의 평균 성과 → 예상 수익률 추정

#### 3.6.3 팩터 중요도 분석

**목적:** 수익률 구간(Level 1~4)에 가장 영향을 주는 팩터 발견

**방법:**
1. **특성 중요도 분석**
   - Random Forest Feature Importance
   - SHAP (SHapley Additive exPlanations)
   - 순열 중요도 (Permutation Importance)
   - **타겟**: `return_level` (0~4) 또는 `peak_return_pct`

2. **상관관계 분석**
   - 각 팩터와 5년 수익률의 상관계수
   - 비선형 관계 탐지 (Mutual Information)
   - Level별 팩터 분포 비교

3. **조합 효과 분석**
   - 여러 팩터의 조합이 미치는 영향
   - 예: "영업이익 5년 증가 + 미래산업 + 초기 6개월 수익률 > 50%"
   - 고수익(Level 3~4)을 만드는 필수 조합 발견

**예상 발견:**
```
중요도 순위 (Level 4 달성 기준):
1. 2번 블록 이후 6개월 수익률 (40%)
2. 영업이익 연속 증가 년수 (25%)
3. 자본총계 연속 증가 년수 (15%)
4. 미래산업 포함 여부 (10%)
5. 외국인/기관 순매수 지속일 (7%)
6. 시장 강세장 여부 (3%)

필수 조합 (Level 4):
- 초기 6개월 수익률 > 50% AND 영업이익 5년 증가 → 확률 85%
- 초기 6개월 수익률 > 30% AND 미래산업 AND 자본총계 3년 증가 → 확률 70%
```

#### 3.6.4 비지도 학습 종합 - 팩터 + 차트 패턴 결합

**목적:** 재무 팩터 + 차트 패턴 클러스터링 결과를 결합하여 투자 전략 수립

**분석 방법:**
1. **팩터 스코어링**:
   - 영업이익 5년 증가: 5점, 3년 증가: 3점, 1년 증가: 1점
   - 자본총계 5년 증가: 5점, 3년 증가: 3점
   - 미래산업 포함: 3점
   - 합산 점수로 등급 분류

2. **차트 패턴 매칭**:
   - DTW로 과거 유사 패턴 찾기
   - 유사 패턴들의 평균 수익률

3. **결합 분석**:
   - 팩터 점수 高 + 차트 패턴 A → Level 4 확률
   - 팩터 점수 中 + 차트 패턴 B → Level 2~3 확률
   - 팩터 점수 低 + 차트 패턴 C → Level 1 확률

**발견된 패턴 → 투자 전략**

**1단계: 1번+2번 블록 발생 (필수 조건)**

**2단계: 팩터 점검 (선호 조건)**
- **Level 4 목표 조건**:
  - 영업이익 5년 연속 증가
  - 자본총계 5년 연속 증가
  - 미래산업 (AI, 2차전지, 바이오 등)
  - 팩터 점수 13점 이상

- **Level 3 목표 조건**:
  - 영업이익 3년 연속 증가
  - 자본총계 3년 연속 증가
  - 미래산업 포함 또는 산업 성장세
  - 팩터 점수 9~12점

- **Level 2 목표 조건**:
  - 영업이익 증가 추세 (연속성 약함)
  - 자본총계 증가
  - 팩터 점수 6~8점

**3단계: 초기 모니터링 (매수 후 3~6개월)**
- **Level 4 기대 차트 패턴**:
  - 초기 6개월 수익률 > 50%
  - 거래량 지속 증가
  - 외국인/기관 순매수 6개월 지속
  - DTW 패턴 매칭 → "급등 후 안정" 패턴

- **Level 3 기대 차트 패턴**:
  - 초기 6개월 수익률 > 30%
  - 거래량 안정적
  - DTW 패턴 매칭 → "완만 상승" 패턴

- **경고 패턴** (손절 고려):
  - 초기 3개월 수익률 < 0%
  - 거래량 급감
  - DTW 패턴 매칭 → "초기 조정" 패턴

**의사결정 매트릭스:**
```
팩터 점수 13+ AND 초기 6개월 수익률 > 50% → Level 4 기대 (보유)
팩터 점수 9~12 AND 초기 6개월 수익률 > 30% → Level 3 기대 (보유)
팩터 점수 6~8 AND 초기 6개월 수익률 > 20% → Level 2 기대 (보유)
팩터 점수 低 OR 초기 3개월 수익률 < 0% → 손절 고려
```

---

### 3.7 지도 학습 (Supervised Learning)

**핵심 목표:** 알려진 성공/실패 패턴 템플릿 기반 신규 케이스 성공 확률 예측

**접근 방식:**

- 이미 알고 있는 2-3개의 **성공 패턴**을 템플릿으로 정의
- 새로운 케이스 발생 시 어느 패턴(성공 또는 실패)을 따를 확률 계산
- DTW 패턴 매칭 + 진행도 모니터링으로 실시간 검증

**학습 방식:**

- **라벨**: 수동으로 정의한 성공/실패 패턴 템플릿
- **예측**: 새 케이스가 성공 패턴 유사도 vs 실패 패턴 유사도 계산
- **결과**: 성공 확률 85% → 매수/보유, 실패 패턴 이탈 → 손절

---

#### 3.7.1 알려진 패턴 정의 및 템플릿화

**목적:** 경험적으로 알고 있는 성공/실패 패턴을 체계화

**배경:**

- 2번 거래량 블록 발생 이후 특정 차트 패턴이 고수익으로 이어진 사례를 경험적으로 알고 있음
- 반대로 실패한 케이스의 공통 패턴도 존재
- 이런 패턴들을 템플릿화하고, 새로운 종목이 같은 패턴으로 진행 중인지 실시간 검증

**패턴 정보 수집:**

- **패턴 이름**: 예) "급등-횡보-재상승 패턴", "계단식 상승 패턴"
- **과거 성공 사례**: 해당 패턴을 보인 종목명 + 날짜
  - 예: 삼성전자 (2019-03-15), 셀트리온 (2020-07-10)
- **수익률 정보**: 2번 블록 고점 대비 최종 수익률
  - 예: 평균 500%, 최소 200%, 최대 1200%

**Step 2: 패턴별 시계열 템플릿 구축**
```python
# 패턴 A: 급등-횡보-재상승 패턴
pattern_a_template = {
    "name": "급등-횡보-재상승 패턴",
    "description": "2번 블록 이후 3개월 내 50% 급등 → 3~6개월 횡보 → 재상승",
    "historical_cases": ["종목A (2019-03)", "종목B (2020-07)"],
    "avg_return": 500,  # %
    "time_series": {
        # 2번 블록 이후 일별 정규화된 수익률 (%)
        "days": [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 360],
        "return_pct": [0, 15, 35, 50, 48, 52, 55, 70, 90, 120, 180, 250, 350],
        "volume_pattern": "초기 고거래량 → 횡보 시 감소 → 재상승 시 증가"
    },
    "key_features": {
        "initial_3m_return": "> 40%",
        "consolidation_period": "3~6개월",
        "second_surge_start": "6~9개월",
        "volume_surge_on_breakout": True
    }
}

# 패턴 B: 계단식 상승 패턴
pattern_b_template = {
    "name": "계단식 상승 패턴",
    "description": "2번 블록 이후 20~30%씩 꾸준히 상승, 조정은 짧고 얕음",
    "historical_cases": ["종목C (2018-05)", "종목D (2021-02)"],
    "avg_return": 300,
    "time_series": {
        "days": [0, 60, 120, 180, 240, 300, 360],
        "return_pct": [0, 20, 50, 80, 120, 180, 250],
        "volume_pattern": "안정적 거래량 유지"
    },
    "key_features": {
        "steady_growth": True,
        "max_drawdown": "< 15%",
        "correction_duration": "< 2주",
        "ma_alignment": "정배열 유지"
    }
}
```

**Step 3: 패턴 시각화 및 문서화**

- 각 패턴의 대표 차트 저장 (이미지 또는 데이터)
- 패턴별 특징 요약표 작성
- 패턴 발생 조건 정의

---

#### 3.7.2 패턴 매칭 알고리즘 (DTW)

**목적:** 새로운 케이스가 알려진 성공/실패 패턴 중 어디에 해당하는지 계산

**Dynamic Time Warping (DTW) 거리 계산:**
```python
from dtaidistance import dtw

def calculate_pattern_similarity(current_timeseries, template_timeseries):
    """
    현재 진행 중인 주가 흐름과 템플릿 패턴의 유사도 계산
    """
    # DTW 거리 계산 (낮을수록 유사)
    distance = dtw.distance(current_timeseries, template_timeseries)

    # 유사도로 변환 (0~1, 1에 가까울수록 유사)
    similarity = 1 / (1 + distance)

    return similarity, distance
```

**다중 특징 매칭:**
```python
def match_pattern_multidimensional(current_case, pattern_template):
    """
    가격뿐 아니라 거래량, 이동평균선 등 다중 특징으로 패턴 매칭
    """
    scores = {}

    # 1) 가격 수익률 패턴 유사도 (DTW)
    scores['price_similarity'] = calculate_pattern_similarity(
        current_case['return_pct'],
        pattern_template['time_series']['return_pct']
    )[0]

    # 2) 거래량 패턴 유사도
    scores['volume_similarity'] = calculate_pattern_similarity(
        current_case['volume_normalized'],
        pattern_template['volume_pattern_ts']
    )[0]

    # 3) 핵심 특징 매칭
    scores['feature_match'] = 0
    if current_case['initial_3m_return'] > 40:  # 패턴 A 조건
        scores['feature_match'] += 0.3
    if current_case['has_consolidation']:
        scores['feature_match'] += 0.3
    # ... 기타 특징 매칭

    # 4) 종합 점수 (가중 평균)
    total_score = (
        scores['price_similarity'] * 0.5 +
        scores['volume_similarity'] * 0.3 +
        scores['feature_match'] * 0.2
    )

    return total_score, scores
```

**패턴 매칭 임계값 설정:**

- **고신뢰 매칭**: 유사도 > 0.80 → "성공 패턴과 매우 유사, 높은 확률로 성공"
- **중신뢰 매칭**: 유사도 0.65~0.80 → "성공 패턴과 유사, 모니터링 지속"
- **저신뢰 매칭**: 유사도 < 0.65 → "패턴 불일치, 실패 패턴 가능성"

---

#### 3.7.3 실시간 패턴 진행도 모니터링

**목적:** 현재 케이스가 성공 패턴을 정상적으로 따라가고 있는지 실시간 검증

**패턴 진행 단계 추적:**
```python
def track_pattern_progress(current_case, pattern_template):
    """
    현재 케이스가 패턴의 어느 단계에 있는지 추적
    """
    days_elapsed = current_case['days_since_block2']
    current_return = current_case['return_pct']

    # 패턴 A: 급등-횡보-재상승
    if pattern_template['name'] == "급등-횡보-재상승 패턴":
        if days_elapsed < 90:
            # Stage 1: 급등 단계
            expected_return = 50  # 3개월 목표
            progress = current_return / expected_return
            stage = "급등 단계"

        elif 90 <= days_elapsed < 180:
            # Stage 2: 횡보 단계
            if 40 <= current_return <= 60:
                stage = "횡보 단계 (정상)"
            else:
                stage = "횡보 단계 (이탈 가능성)"
            progress = 0.5  # 전체 패턴의 50% 진행

        elif days_elapsed >= 180:
            # Stage 3: 재상승 단계
            expected_return = 350  # 1년 목표
            progress = current_return / expected_return
            stage = "재상승 단계"

    return {
        "stage": stage,
        "progress": progress,
        "is_on_track": progress > 0.8,  # 기대치의 80% 이상이면 정상
        "days_elapsed": days_elapsed
    }
```

**이탈 알림 (Deviation Alert):**
```python
def check_pattern_deviation(current_case, pattern_template):
    """
    패턴에서 벗어나는지 체크
    """
    alerts = []

    # 1) 수익률 이탈
    expected_return = get_expected_return(
        pattern_template,
        current_case['days_since_block2']
    )
    actual_return = current_case['return_pct']

    if actual_return < expected_return * 0.7:  # 기대치의 70% 미만
        alerts.append({
            "type": "RETURN_UNDERPERFORMANCE",
            "severity": "WARNING",
            "message": f"수익률 저조: 기대 {expected_return}% vs 실제 {actual_return}%"
        })

    # 2) 거래량 이탈
    if current_case['volume_trend'] == "급감" and pattern_template['requires_volume']:
        alerts.append({
            "type": "VOLUME_DROP",
            "severity": "WARNING",
            "message": "거래량 급감, 패턴 이탈 가능성"
        })

    # 3) MDD 초과
    if current_case['max_drawdown'] > pattern_template['key_features'].get('max_drawdown', 20):
        alerts.append({
            "type": "EXCESSIVE_DRAWDOWN",
            "severity": "CRITICAL",
            "message": f"MDD 초과: {current_case['max_drawdown']}%"
        })

    return alerts
```

---

#### 3.7.4 새로운 케이스 자동 스크리닝 및 예측

**목적:** 2번 블록 발생 즉시 성공 확률 예측 및 투자 의사결정

**2번 블록 발생 시 자동 패턴 매칭:**
```python
def auto_screen_new_case(ticker, block2_date):
    """
    2번 거래량 블록 발생 시 자동으로 알려진 패턴 매칭 시도
    """
    # 1) 초기 데이터 수집 (2번 블록 이후 30일)
    initial_data = collect_initial_data(ticker, block2_date, days=30)

    # 2) 모든 알려진 패턴과 비교
    pattern_matches = []
    for pattern in [pattern_a_template, pattern_b_template]:
        score, details = match_pattern_multidimensional(initial_data, pattern)
        pattern_matches.append({
            "pattern_name": pattern['name'],
            "similarity_score": score,
            "expected_return": pattern['avg_return'],
            "details": details
        })

    # 3) 가장 유사한 패턴 선택
    best_match = max(pattern_matches, key=lambda x: x['similarity_score'])

    # 4) 알림 생성
    if best_match['similarity_score'] > 0.70:
        notification = {
            "ticker": ticker,
            "message": f"'{best_match['pattern_name']}' 패턴 감지 (유사도 {best_match['similarity_score']:.2%})",
            "expected_return": best_match['expected_return'],
            "action": "모니터링 시작"
        }
        send_notification(notification)

    return best_match
```

**주기적 업데이트 및 재평가:**
```python
def periodic_pattern_check(ticker):
    """
    진행 중인 케이스의 패턴 일치도 주기적 재계산
    """
    current_data = get_current_data(ticker)
    assigned_pattern = get_assigned_pattern(ticker)

    # 1) 패턴 진행도 체크
    progress = track_pattern_progress(current_data, assigned_pattern)

    # 2) 이탈 여부 체크
    alerts = check_pattern_deviation(current_data, assigned_pattern)

    # 3) 보고서 생성
    report = {
        "ticker": ticker,
        "pattern": assigned_pattern['name'],
        "stage": progress['stage'],
        "is_on_track": progress['is_on_track'],
        "alerts": alerts,
        "current_return": current_data['return_pct'],
        "days_elapsed": current_data['days_since_block2']
    }

    # 4) 이탈 시 알림
    if len(alerts) > 0:
        send_alert(report)

    return report
```

---

#### 3.7.5 반지도 학습으로 패턴 정교화

**목적:** 알려진 패턴을 Seed로 사용하여 패턴 템플릿을 점진적으로 개선

**알려진 패턴을 Seed로 사용:**

- 초기: 2-3개의 알려진 패턴 (수동 라벨링)
- 비지도 학습(3.6)으로 발견된 클러스터 중 유사한 케이스 자동 병합
- 패턴 템플릿 점진적 업데이트

**패턴 라이브러리 확장:**
```python
def refine_pattern_with_new_cases(pattern_template, similar_cases):
    """
    유사한 케이스들을 추가하여 패턴 템플릿 정교화
    """
    # 1) 새로운 케이스들의 평균 시계열 계산
    new_timeseries = calculate_average_timeseries(similar_cases)

    # 2) 기존 템플릿과 가중 평균
    updated_timeseries = (
        pattern_template['time_series'] * 0.7 +
        new_timeseries * 0.3
    )

    # 3) 수익률 통계 업데이트
    pattern_template['avg_return'] = np.mean([c['return'] for c in similar_cases])
    pattern_template['min_return'] = np.min([c['return'] for c in similar_cases])
    pattern_template['max_return'] = np.max([c['return'] for c in similar_cases])

    # 4) 신뢰도 증가
    pattern_template['sample_size'] += len(similar_cases)

    return pattern_template
```

---

#### 3.7.6 시각화 및 대시보드

**목적:** 패턴 진행 상황을 직관적으로 모니터링

**패턴 진행도 차트:**

- 현재 주가 흐름 (실선)
- 예상 패턴 템플릿 (점선)
- 신뢰 구간 (음영)
- 이탈 지점 표시 (빨간 점)

**실시간 모니터링 대시보드:**
```
┌─────────────────────────────────────────────┐
│ 진행 중인 패턴 매칭 케이스                    │
├─────────────────────────────────────────────┤
│ 종목: 삼성전자                               │
│ 패턴: 급등-횡보-재상승 패턴                   │
│ 유사도: 87%                                  │
│ 진행 단계: 횡보 단계 (2/3)                   │
│ 경과일: 125일                                │
│ 현재 수익률: +52%                            │
│ 예상 수익률: +48% (정상 범위)                │
│ 상태: ✅ 정상 진행 중                        │
│ 다음 단계: 재상승 예상 (30~60일 후)          │
└─────────────────────────────────────────────┘
```

---

---

#### 3.7.7 지도 학습 종합 워크플로우

```
1번+2번 블록 발생
    ↓
[자동 스크리닝]
알려진 패턴 A, B, C와 매칭 시도
    ↓
유사도 > 70% 발견
    ↓
[알림] "패턴 A 감지! 평균 수익률 500%"
    ↓
[모니터링 시작]
매일/매주 패턴 진행도 체크
    ↓
정상 진행 중?
    ├─ YES → 보유 지속, 예상 수익률 업데이트
    └─ NO → 이탈 알림, 손절 또는 전략 재평가
    ↓
패턴 완성 시
    ↓
실제 수익률 기록 → 패턴 템플릿 업데이트
```

**기대 효과:**

- **자동화**: 2번 블록 발생 즉시 알려진 패턴 자동 매칭 및 성공 확률 예측
- **조기 경보**: 패턴 이탈 시 즉시 알림으로 리스크 관리
- **확신 증가**: 과거 성공 패턴과 유사할 때 보유 확신 강화 (유사도 87% → 성공 확률 85%)
- **패턴 학습**: 새로운 케이스로 패턴 템플릿 지속 개선

---

### 3.8 개발 단계별 계획

**Phase 1: 데이터 수집 및 블록 탐지 (4주)**
- 10년간 전체 종목 OHLCV 데이터 수집 (KOSPI + KOSDAQ)
- 재무제표 데이터 수집 (영업이익, 자본총계, ROE 등)
- 산업 분류 데이터 수집
- 1번 거래량 블록 탐지 알고리즘 구현
- 2번 거래량 블록 탐지 알고리즘 구현
- 1번+2번 블록 케이스 추출 (예상 100~500개)

**Phase 2: 성과 추적 및 라벨링 (3주)**
- 각 케이스별 5년간 주가 흐름 데이터 수집
  - 일별 데이터 (첫 1년)
  - 주별 데이터 (5년 전체)
- 2번 블록 고점 대비 100% 달성 여부 라벨링
- 최고 수익률, MDD, 조정 패턴 등 지표 계산
- 데이터셋 구축:
  - 특성 벡터 (블록, 재무, 산업, 수급, 시장)
  - 라벨 (is_100pct_success, peak_return_pct 등)

**Phase 3: 비지도 학습 - 패턴 발견 (4주)**
- 클러스터링 (K-means, DBSCAN, Hierarchical)
- 고성공/중성공/저성공 클러스터 분석
- 각 클러스터의 차별 요인 발견
- 주가 흐름 패턴 시각화 및 분석
- 시계열 클러스터링 (DTW)
- 팩터 중요도 분석 (Random Forest, SHAP)

**Phase 4: 전략 수립 및 백테스팅 (3주)**
- 발견된 패턴 기반 투자 전략 수립
  - 필수 조건: 1번+2번 블록
  - 선호 조건: 영업이익/자본총계 증가, 미래산업 등
  - 모니터링 지표: 초기 3개월 수익률, 거래량 등
- 전략 백테스팅 (10년)
- 성과 분석:
  - 100% 달성 확률
  - 평균 수익률 및 기간
  - MDD, 샤프 비율
- 전략 개선 및 최적화

**Phase 5: 문서화 및 시스템 구축 (2주)**
- 분석 결과 문서화
- 실시간 모니터링 시스템 구축
  - 1번+2번 블록 자동 탐지
  - 선호 조건 체크
  - 알림 시스템
- 최종 검토 및 배포

---

## 4. 기술 스택

### 4.1 언어 및 프레임워크
- **Python 3.x**
- 데이터 처리: pandas, numpy
- 시각화: matplotlib, seaborn, plotly
- 머신러닝: scikit-learn, xgboost, lightgbm
- 딥러닝: TensorFlow/Keras 또는 PyTorch
- 백테스팅: backtrader, zipline

### 4.2 데이터베이스
- PostgreSQL 또는 SQLite (데이터 저장)
- Redis (캐싱, 선택사항)

### 4.3 API
- 한국투자증권 API
- FinanceDataReader
- yfinance (해외 데이터 참고용)

## 5. 개발 일정

### Phase 1: 데이터 수집 및 인프라 구축 (3주)
- [ ] 개발 환경 설정 (Python, pandas, pykrx, dart-fss 등)
- [ ] 데이터 수집 API 연동
  - [ ] pykrx로 주가/거래/수급 데이터 수집
  - [ ] dart-fss로 재무제표 데이터 수집
  - [ ] pytrends로 검색 트렌드 데이터 수집
- [ ] 데이터베이스 설계 및 구축
- [ ] 10년치 KOSPI/KOSDAQ 전체 종목 데이터 수집
- [ ] **60일 이동평균선 계산 모듈 구현**
- [ ] **2년래 최대 거래량 탐지 알고리즘 구현**

### Phase 2: 거래량 블록 탐지 및 케이스 수집 (3주)
- [ ] **1번 거래량 블록 탐지 알고리즘 구현**
  - [ ] 2년래 최대 거래량 검증
  - [ ] 거래대금 500억원 이상 필터
  - [ ] D일 당일 수급 데이터 수집 (스냅샷)
  - [ ] 2년래 신고가 분석
- [ ] **2번 거래량 블록 탐지 알고리즘 구현**
  - [ ] 1번 블록 대비 80% 거래량 검증
  - [ ] 6개월 내 발생 확인
  - [ ] D+D+1, D+D+2, D+D+1+D+2 패턴 매칭
  - [ ] 4가지 필수 조건 검증 (고가 돌파, 거래대금, 패턴, 14일)
  - [ ] D, D+1, D+2 당일 수급 데이터 수집
  - [ ] 2년/5년/10년/역사적 신고가 분석
- [ ] **60이평선 기반 블록 범위 탐지**
  - [ ] 블록 종료일 탐지 (터치/하방이탈)
  - [ ] 블록 최고가 추출 (수익률 기준점)
- [ ] 1번+2번 블록 케이스 수집 (예상 100~500개)
- [ ] 데이터 품질 검증

### Phase 3: 트렌드 데이터 수집 및 통합 (2주)
- [ ] **재무제표 트렌드 데이터 수집**
  - [ ] 1번 블록 D일 기준 2년 전 ~ 현재까지
  - [ ] 영업이익, 자본총계, ROE/ROA 추이
  - [ ] 적자→흑자 전환 탐지
- [ ] **수급 트렌드 데이터 수집 (기간 분석)**
  - [ ] 2번 블록 D일 ~ 현재까지
  - [ ] 외국인/기관/개인 순매수 추세
  - [ ] 연속 매수일, 보유비중 변화
  - [ ] 수급 균형 점수 계산
  - [ ] 공매도/프로그램 매매 데이터
- [ ] **산업 트렌드 데이터 수집**
  - [ ] 1번 블록 D일 기준 2년 전 ~ 현재까지
  - [ ] 검색 트렌드 (네이버/구글)
  - [ ] 뉴스 감성 분석
  - [ ] 미래 산업 분류
  - [ ] R&D, 특허, 정부 지원금 데이터
- [ ] **장기 가격 흐름 데이터 (라벨링용)**
  - [ ] 2번 블록 고점 기준 5년간 추적
  - [ ] 수익률 구간 분류 (Level 0~4)
  - [ ] **기간 분석**: 50%/100% 도달 소요 일수
  - [ ] **MDD 분석**: 블록 고점 대비 최대 하락률 및 발생 시점
  - [ ] **실패 케이스 분석**: 지속 하락 패턴, 5년 후 최종 수익률
  - [ ] **리스크-수익 프로파일**: 리스크-수익 비율 계산
- [ ] 전체 데이터셋 통합 및 검증

### Phase 4: 비지도 학습 - 패턴 발견 (3주)
- [ ] **Step 1: 성공 vs 실패 팩터 분석 (Level 0 vs 1~4)**
  - [ ] 전체 케이스를 성공/실패로 2분류
  - [ ] Random Forest로 성공/실패 결정 팩터 추출
  - [ ] SHAP으로 팩터 순위화
  - [ ] 통계적 검정 (t-test, Mann-Whitney U)
  - [ ] **핵심 질문**: 수익 발생(50%+)에 결정적인 팩터는?
    - [ ] 신고가 등급의 임계값은? (C 이상?)
    - [ ] 외국인+기관 순매수 필수인가?
    - [ ] 재무 턴어라운드가 필요한가?
    - [ ] 미래 산업 여부의 영향은?
  - [ ] 실패 케이스(Level 0)의 공통 약점 분석

- [ ] **Step 2: 성공 케이스 내 Level별 차별 팩터 분석**
  - [ ] 성공 케이스(Level 1~4)만 필터링
  - [ ] K-means, DBSCAN, Hierarchical 클러스터링
  - [ ] PCA, t-SNE, UMAP으로 Level 분포 시각화
  - [ ] Random Forest 회귀로 Level 결정 팩터 추출
  - [ ] SHAP으로 고수익(Level 3~4) 조건 분석
  - [ ] **핵심 질문**: Level 1→4로 갈수록 강화되는 팩터는?
    - [ ] 신고가 등급의 상승 효과 (C→B→A→S)
    - [ ] 외국인+기관 순매수 금액 규모
    - [ ] 재무 개선 폭 (영업이익률, 자본총계)
    - [ ] 미래 산업 점수
    - [ ] 검색 트렌드/미디어 노출
  - [ ] 초고수익(Level 4) 케이스의 특별한 조건

- [ ] **Step 3: 시간/리스크 팩터 분석**
  - [ ] 수익률-기간-MDD 3차원 클러스터링
  - [ ] "고수익-빠름-낮은MDD" vs "고수익-느림-높은MDD" 구분
  - [ ] **수익 실현 기간**: 50% 도달까지 평균 기간, Level별 차이
  - [ ] **최대 낙폭(MDD)**: 블록 고점 대비 평균 하락률, Level별 차이
  - [ ] **리스크-수익 비율**: 최적 프로파일의 특징

- [ ] **종합 분석 리포트 작성**
  - [ ] 성공/실패 결정 팩터 정리 (필수/중요/선호 조건)
  - [ ] Level별 차별 팩터 정리 (Level 1→2→3→4 조건)
  - [ ] 실패 케이스 패턴 정리

### Phase 5: 지도 학습 - 성공 패턴 예측 모델 (3주)
- [ ] **데이터 라벨링 및 분할**
  - [ ] 성공/실패 라벨링 (50% 기준)
  - [ ] Level 0~4 분류
  - [ ] **기간 분류**: 초단기/단기/중기/장기/미달성
  - [ ] **MDD 심각도**: 경미/보통/심각/매우심각
  - [ ] **실패 케이스 분석**: 지속 하락 패턴 분류
  - [ ] Train/Validation/Test 분할
- [ ] **특성 벡터 구성**
  - [ ] 거래량 블록, 신고가, 당일 수급, 수급 트렌드
  - [ ] 재무제표, 산업 트렌드
- [ ] **모델 학습 및 비교**
  - [ ] 분류 모델: Random Forest, XGBoost, LightGBM
  - [ ] 회귀 모델: Gradient Boosting, LSTM
  - [ ] Multi-class 분류 (Level 0~4)
  - [ ] **기간 예측 모델**: 50% 도달 소요 일수 회귀
  - [ ] **MDD 예측 모델**: 최대 하락률 회귀
- [ ] **모델 평가**
  - [ ] Accuracy, Precision, Recall, F1-score
  - [ ] ROC-AUC, Confusion Matrix
  - [ ] 수익률 예측 정확도 (RMSE, MAE)
  - [ ] **기간 예측 정확도**: 50% 도달 일수 오차
  - [ ] **MDD 예측 정확도**: 하락률 오차
  - [ ] **실패 케이스 예측**: 정밀도/재현율
- [ ] **하이퍼파라미터 튜닝**

### Phase 6: 백테스팅 및 전략 검증 (2주)
- [ ] 백테스팅 프레임워크 구축
- [ ] 과거 10년 데이터 기반 전략 검증
  - [ ] 50% 달성 확률 검증
  - [ ] Level 2 이상 달성률
  - [ ] 평균 수익률 및 소요 기간
  - [ ] **기간 분석**: 50% 도달까지 평균 일수, 분포
  - [ ] **MDD 분석**: 평균 최대 하락률, 발생 시점
- [ ] 리스크 분석
  - [ ] MDD, 샤프 비율
  - [ ] 리스크-수익 비율 분포
  - [ ] **실패 케이스 분석**
    - [ ] 실패율 (50% 미달성)
    - [ ] 실패 시 평균 하락폭
    - [ ] 지속 하락 패턴 비율
- [ ] 성과 보고서 작성
  - [ ] 수익률/기간/리스크 종합 분석
  - [ ] Level별 성과 비교
  - [ ] 실패 케이스 패턴 정리

### Phase 7: 최적화 및 배포 (2주)
- [ ] 모델 최적화
- [ ] **실시간 모니터링 시스템 구축**
  - [ ] 1번+2번 블록 자동 탐지
  - [ ] 성공 확률 계산
  - [ ] 알림 시스템
- [ ] 문서화
- [ ] 최종 검토 및 배포

**총 예상 기간**: 18주 (약 4.5개월)

## 5. 프로젝트 구조

```
robostock/
├── data/                   # 데이터 저장
│   ├── raw/               # 원본 데이터
│   ├── processed/         # 전처리된 데이터
│   └── features/          # 특성 데이터
├── src/                   # 소스 코드
│   ├── data_collection/   # 데이터 수집
│   ├── preprocessing/     # 전처리
│   ├── features/          # 특성 엔지니어링
│   ├── models/            # 모델
│   ├── backtesting/       # 백테스팅
│   └── utils/             # 유틸리티
├── notebooks/             # Jupyter 노트북
├── tests/                 # 테스트 코드
├── config/                # 설정 파일
├── docs/                  # 문서
├── requirements.txt       # 의존성
└── README.md
```

## 6. 성과 지표

### 6.1 모델 성능
- 예측 정확도 (Accuracy)
- 정밀도 (Precision), 재현율 (Recall)
- F1 Score
- AUC-ROC

### 6.2 투자 성과
- 연평균 수익률 (CAGR)
- 샤프 비율 (Sharpe Ratio)
- 최대 낙폭 (MDD)
- 승률 (Win Rate)
- 손익비 (Profit Factor)

### 6.3 목표 성과
- 연평균 수익률: 10% 이상
- 샤프 비율: 1.0 이상
- 최대 낙폭: 20% 이하
- 승률: 55% 이상

## 7. 리스크 관리

### 7.1 기술적 리스크
- 데이터 품질 문제
- 과적합 (Overfitting)
- 컴퓨팅 리소스 부족

### 7.2 대응 방안
- 데이터 검증 프로세스 강화
- 교차 검증 (Cross-validation) 적용
- 클라우드 서비스 활용 검토

### 7.3 투자 리스크
- 시장 급변 대응
- 포트폴리오 다각화
- 손절매 규칙 설정

## 8. 향후 계획

### 8.1 단기 (3개월)
- 기본 모델 개발 및 백테스팅 완료
- 초기 성과 분석

### 8.2 중기 (6개월)
- 모델 개선 및 최적화
- 실전 투자 소규모 적용
- 성과 모니터링

### 8.3 장기 (1년+)
- 다양한 전략 추가
- 해외 주식 시장 확장
- 자동 매매 시스템 구축

## 9. 참고 사항

- 본 모델은 투자 참고용이며, 투자 손실에 대한 책임은 투자자 본인에게 있습니다
- 과거 데이터 기반 모델이므로 미래 수익을 보장하지 않습니다
- 지속적인 모델 업데이트 및 시장 모니터링이 필요합니다
